Start testing on iteration 2499
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.711s + 0.001s (eta: 0:07:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.598s + 0.001s (eta: 0:06:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.570s + 0.001s (eta: 0:05:41)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.547s + 0.001s (eta: 0:05:22)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.541s + 0.001s (eta: 0:05:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.537s + 0.001s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.541s + 0.001s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.536s + 0.002s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.529s + 0.002s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.526s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.527s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.524s + 0.003s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.521s + 0.003s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.520s + 0.003s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.519s + 0.003s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.516s + 0.003s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.516s + 0.003s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.513s + 0.003s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.513s + 0.003s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.514s + 0.003s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.513s + 0.003s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.512s + 0.003s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.513s + 0.003s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.512s + 0.003s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.510s + 0.003s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.511s + 0.003s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.511s + 0.003s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.510s + 0.003s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.508s + 0.003s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.508s + 0.003s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.507s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.507s + 0.003s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.506s + 0.003s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.505s + 0.003s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.505s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.506s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.506s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.505s + 0.003s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.505s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.506s + 0.003s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.505s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.506s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.506s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.506s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.505s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.506s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.505s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.506s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.506s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.506s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.505s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.505s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.505s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.505s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.506s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.506s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.507s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.507s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.506s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.506s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.507s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.507s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.952s + 0.002s (eta: 0:09:49)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.520s + 0.002s (eta: 0:05:17)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.504s + 0.002s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.519s + 0.002s (eta: 0:05:06)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.504s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.513s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.513s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.509s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.508s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.504s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.503s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.500s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.498s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.502s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.501s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.504s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.504s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.505s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.503s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.502s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.503s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.505s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.506s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.506s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.508s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.511s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.511s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.509s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.508s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.509s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.509s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.509s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.509s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.508s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.507s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.507s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.507s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.507s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.507s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.507s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.508s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.508s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.509s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.509s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.509s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.508s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.508s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.508s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.508s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.507s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.508s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.508s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.508s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.508s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.508s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.508s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.508s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.507s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.507s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.507s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.506s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.505s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.678s + 0.001s (eta: 0:06:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.525s + 0.001s (eta: 0:05:20)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.517s + 0.001s (eta: 0:05:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.516s + 0.001s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.515s + 0.001s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.507s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.517s + 0.002s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.517s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.516s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.517s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.512s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.514s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.517s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.517s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.516s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.513s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.511s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.513s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.511s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.512s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.511s + 0.002s (eta: 0:03:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.511s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.511s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.513s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.515s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.517s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.516s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.516s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.517s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.516s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.516s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.515s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.515s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.515s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.514s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.512s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.512s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.512s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.512s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.511s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.511s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.511s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.511s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.510s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.509s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.510s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.510s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.509s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.510s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.510s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.510s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.510s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.509s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.509s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.509s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.508s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.509s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.508s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.508s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.767s + 0.002s (eta: 0:07:54)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.481s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.459s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.475s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.479s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.486s + 0.001s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.489s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.486s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.485s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.488s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.488s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.489s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.492s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.492s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.493s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.494s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.492s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.494s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.495s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.495s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.496s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.497s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.496s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.496s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.497s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.498s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.497s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.498s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.498s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.498s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.498s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.498s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.497s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.499s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.498s + 0.002s (eta: 0:02:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.498s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.496s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.496s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.496s + 0.002s (eta: 0:01:58)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.496s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.497s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.496s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.497s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.496s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.498s + 0.002s (eta: 0:01:28)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.497s + 0.002s (eta: 0:01:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.497s + 0.002s (eta: 0:01:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.497s + 0.002s (eta: 0:01:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.497s + 0.002s (eta: 0:01:08)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.497s + 0.002s (eta: 0:01:03)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.498s + 0.002s (eta: 0:00:58)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.498s + 0.002s (eta: 0:00:53)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.498s + 0.002s (eta: 0:00:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.498s + 0.002s (eta: 0:00:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.497s + 0.002s (eta: 0:00:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.497s + 0.002s (eta: 0:00:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.497s + 0.002s (eta: 0:00:28)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.498s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.499s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.499s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.499s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.500s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.630s + 0.001s (eta: 0:06:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.503s + 0.001s (eta: 0:05:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.528s + 0.001s (eta: 0:05:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.519s + 0.001s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.509s + 0.002s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.509s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.510s + 0.002s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.509s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.510s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.506s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.505s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.505s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.503s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.503s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.502s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.502s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.502s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.502s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.502s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.504s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.504s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.503s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.501s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.501s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.500s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.498s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.496s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.497s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.498s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.498s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.498s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.499s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.498s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.498s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.498s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.499s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.500s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.499s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.499s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.500s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.500s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.500s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.500s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.501s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.501s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.500s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.500s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.500s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.500s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.500s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.500s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.500s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.501s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.500s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.500s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.499s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.500s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.500s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.500s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.501s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.501s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.501s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.624s + 0.001s (eta: 0:06:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.504s + 0.001s (eta: 0:05:07)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.505s + 0.003s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.515s + 0.003s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.511s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.512s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.511s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.514s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.516s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.523s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.524s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.524s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.520s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.517s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.516s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.518s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.519s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.522s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.523s + 0.002s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.519s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.520s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.520s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.518s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.515s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.515s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.515s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.517s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.515s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.515s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.514s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.514s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.512s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.511s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.509s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.509s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.509s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.508s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.509s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.509s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.510s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.510s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.510s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.509s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.508s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.508s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.508s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.508s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.509s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.508s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.508s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.508s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.508s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.509s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.509s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.509s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.508s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.507s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.507s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.507s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.507s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.506s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.507s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.694s + 0.002s (eta: 0:07:10)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.514s + 0.002s (eta: 0:05:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.533s + 0.003s (eta: 0:05:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.529s + 0.003s (eta: 0:05:12)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.519s + 0.003s (eta: 0:05:01)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.524s + 0.003s (eta: 0:04:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.526s + 0.003s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.525s + 0.003s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.525s + 0.003s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.522s + 0.003s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.524s + 0.003s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.523s + 0.003s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.521s + 0.003s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.521s + 0.003s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.520s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.521s + 0.003s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.516s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.515s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.513s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.513s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.513s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.514s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.513s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.513s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.512s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.512s + 0.003s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.511s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.511s + 0.003s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.510s + 0.003s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.511s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.512s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.512s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.512s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.511s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.512s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.512s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.512s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.512s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.512s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.513s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.513s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.513s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.513s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.513s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.514s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.514s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.513s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.514s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.513s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.513s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.513s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.513s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.513s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.513s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.512s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.512s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.512s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.512s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.511s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.511s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.511s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.510s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step2499.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.514s + 0.001s (eta: 0:05:18)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.491s + 0.003s (eta: 0:04:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.502s + 0.003s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.495s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.494s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.494s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.490s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.490s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.495s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.497s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.496s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.494s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.496s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.497s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.498s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.498s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.499s + 0.002s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.501s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.501s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.501s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.501s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.500s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.499s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.500s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.502s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.500s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.501s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.501s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.500s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.502s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.503s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.503s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.505s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.506s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.506s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.506s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.506s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.506s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.506s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.506s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.506s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.507s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.507s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.507s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.508s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.507s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.508s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.507s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.507s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.506s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.505s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.506s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.507s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.506s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.506s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.507s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.506s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.507s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.506s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.507s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.507s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.506s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 334.113s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [ 255 1718  992 ...   35 1898 1527]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.8405
INFO voc_eval.py: 171: [1295 1977 1000 ...  797  351 1455]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8383
INFO voc_eval.py: 171: [1355 1451 1720 ... 1984  414  976]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.8051
INFO voc_eval.py: 171: [ 919 3239 2308 ... 1694 1076 1234]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6744
INFO voc_eval.py: 171: [1068  945 1534 ...  810    6  262]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.7098
INFO voc_eval.py: 171: [ 122  996  966 ...  175  517 1548]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.8554
INFO voc_eval.py: 171: [4229 2512 3571 ... 1327 7251 3536]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8760
INFO voc_eval.py: 171: [1331  566  339 ...  597    5  799]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8728
INFO voc_eval.py: 171: [ 209  207 4330 ... 3205 4646 1669]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6528
INFO voc_eval.py: 171: [1457  344 1182 ... 1562  773  906]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.8048
INFO voc_eval.py: 171: [1190 3449 2291 ... 1710  962 3673]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.7357
INFO voc_eval.py: 171: [1553  939 1354 ... 1421 1754  138]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8570
INFO voc_eval.py: 171: [1302  146  705 ...  722   67  349]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8458
INFO voc_eval.py: 171: [ 510 1683  796 ... 1267 1459 1627]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.8228
INFO voc_eval.py: 171: [ 5120  5614 16378 ...  9555 13549 21065]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8549
INFO voc_eval.py: 171: [3956 4191 5275 ... 1267 3623 4081]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.5508
INFO voc_eval.py: 171: [1173  259   71 ...  292 1352  352]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.8078
INFO voc_eval.py: 171: [ 392 1222  638 ...  571 2037 1432]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7680
INFO voc_eval.py: 171: [1059 1526  942 ... 1371 1599 1166]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.8442
INFO voc_eval.py: 171: [1250  898  495 ... 1694  800  868]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7825
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7900
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.841
INFO voc_dataset_evaluator.py: 134: 0.838
INFO voc_dataset_evaluator.py: 134: 0.805
INFO voc_dataset_evaluator.py: 134: 0.674
INFO voc_dataset_evaluator.py: 134: 0.710
INFO voc_dataset_evaluator.py: 134: 0.855
INFO voc_dataset_evaluator.py: 134: 0.876
INFO voc_dataset_evaluator.py: 134: 0.873
INFO voc_dataset_evaluator.py: 134: 0.653
INFO voc_dataset_evaluator.py: 134: 0.805
INFO voc_dataset_evaluator.py: 134: 0.736
INFO voc_dataset_evaluator.py: 134: 0.857
INFO voc_dataset_evaluator.py: 134: 0.846
INFO voc_dataset_evaluator.py: 134: 0.823
INFO voc_dataset_evaluator.py: 134: 0.855
INFO voc_dataset_evaluator.py: 134: 0.551
INFO voc_dataset_evaluator.py: 134: 0.808
INFO voc_dataset_evaluator.py: 134: 0.768
INFO voc_dataset_evaluator.py: 134: 0.844
INFO voc_dataset_evaluator.py: 134: 0.782
INFO voc_dataset_evaluator.py: 135: 0.790
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
Start testing on iteration 4999
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.653s + 0.002s (eta: 0:06:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.534s + 0.006s (eta: 0:05:28)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.529s + 0.004s (eta: 0:05:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.519s + 0.004s (eta: 0:05:07)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.522s + 0.003s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.518s + 0.003s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.517s + 0.003s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.516s + 0.003s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.512s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.511s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.504s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.502s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.503s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.503s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.504s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.502s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.502s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.502s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.504s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.503s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.503s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.502s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.505s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.505s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.507s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.508s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.507s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.504s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.505s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.506s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.506s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.505s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.507s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.506s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.506s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.505s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.505s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.506s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.507s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.505s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.505s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.505s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.505s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.506s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.507s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.507s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.508s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.507s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.507s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.507s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.507s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.507s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.508s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.507s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.507s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.508s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.508s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.507s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.507s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.536s + 0.001s (eta: 0:05:31)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.482s + 0.002s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.488s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.494s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.510s + 0.002s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.508s + 0.002s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.502s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.497s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.501s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.505s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.515s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.513s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.511s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.509s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.509s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.509s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.509s + 0.002s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.508s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.505s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.505s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.506s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.507s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.505s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.505s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.506s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.507s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.506s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.506s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.506s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.504s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.504s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.503s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.503s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.504s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.504s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.504s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.505s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.506s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.506s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.505s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.505s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.505s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.505s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.505s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.506s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.505s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.505s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.506s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.506s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.506s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.505s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.505s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.506s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.506s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.507s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.507s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.507s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.507s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.507s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.506s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.579s + 0.001s (eta: 0:05:58)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.471s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.495s + 0.002s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.502s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.495s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.503s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.498s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.497s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.495s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.498s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.496s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.498s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.495s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.498s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.500s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.502s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.500s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.500s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.500s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.500s + 0.002s (eta: 0:03:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.501s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.503s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.505s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.506s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.506s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.505s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.504s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.506s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.506s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.505s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.505s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.504s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.503s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.504s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.503s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.503s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.502s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.501s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.501s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.499s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.499s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.498s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.498s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.498s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.498s + 0.002s (eta: 0:01:28)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.498s + 0.002s (eta: 0:01:23)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.498s + 0.002s (eta: 0:01:18)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.497s + 0.002s (eta: 0:01:13)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.497s + 0.002s (eta: 0:01:08)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.496s + 0.002s (eta: 0:01:03)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.496s + 0.002s (eta: 0:00:58)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.496s + 0.002s (eta: 0:00:53)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.496s + 0.002s (eta: 0:00:48)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.495s + 0.002s (eta: 0:00:43)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.495s + 0.002s (eta: 0:00:38)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.494s + 0.002s (eta: 0:00:33)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.494s + 0.002s (eta: 0:00:28)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.494s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.494s + 0.002s (eta: 0:00:18)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.494s + 0.002s (eta: 0:00:13)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.493s + 0.002s (eta: 0:00:08)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.493s + 0.002s (eta: 0:00:03)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.536s + 0.001s (eta: 0:05:32)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.507s + 0.002s (eta: 0:05:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.520s + 0.001s (eta: 0:05:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.511s + 0.002s (eta: 0:05:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.507s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.500s + 0.002s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.498s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.496s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.493s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.496s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.500s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.504s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.506s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.505s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.504s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.505s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.505s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.507s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.508s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.508s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.509s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.509s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.508s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.508s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.508s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.507s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.507s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.508s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.509s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.508s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.508s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.509s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.510s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.511s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.511s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.512s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.512s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.512s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.512s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.512s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.511s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.512s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.513s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.512s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.511s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.512s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.512s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.513s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.513s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.512s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.512s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.512s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.513s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.513s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.513s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.514s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.514s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.514s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.515s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.515s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.514s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.513s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.643s + 0.002s (eta: 0:06:38)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.532s + 0.002s (eta: 0:05:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.517s + 0.001s (eta: 0:05:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.515s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.506s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.514s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.525s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.521s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.519s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.519s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.521s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.518s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.514s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.513s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.512s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.513s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.514s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.514s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.512s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.511s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.510s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.509s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.510s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.511s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.511s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.512s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.511s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.510s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.511s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.511s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.510s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.510s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.509s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.508s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.508s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.506s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.507s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.506s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.506s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.505s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.506s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.505s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.504s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.505s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.505s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.504s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.503s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.503s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.503s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.502s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.502s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.501s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.501s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.500s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.501s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.501s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.500s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.500s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.499s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.499s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.499s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.499s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.713s + 0.002s (eta: 0:07:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.512s + 0.003s (eta: 0:05:12)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.502s + 0.002s (eta: 0:05:01)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.502s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.501s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.502s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.509s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.514s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.512s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.509s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.510s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.505s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.511s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.509s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.508s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.506s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.503s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.501s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.502s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.501s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.503s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.503s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.502s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.503s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.503s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.503s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.503s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.504s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.502s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.503s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.502s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.503s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.500s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.500s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.501s + 0.002s (eta: 0:02:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.501s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.501s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.500s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.501s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.501s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.501s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.501s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.501s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.501s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.500s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.500s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.500s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.499s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.500s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.499s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.499s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.499s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.498s + 0.002s (eta: 0:00:48)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.498s + 0.002s (eta: 0:00:43)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.498s + 0.002s (eta: 0:00:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.497s + 0.002s (eta: 0:00:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.497s + 0.002s (eta: 0:00:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.497s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.496s + 0.002s (eta: 0:00:18)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.496s + 0.002s (eta: 0:00:13)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.496s + 0.002s (eta: 0:00:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.496s + 0.002s (eta: 0:00:03)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.689s + 0.012s (eta: 0:07:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.571s + 0.003s (eta: 0:05:48)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.558s + 0.002s (eta: 0:05:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.548s + 0.002s (eta: 0:05:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.537s + 0.002s (eta: 0:05:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.524s + 0.002s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.518s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.522s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.522s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.519s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.521s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.524s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.526s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.526s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.524s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.526s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.525s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.522s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.523s + 0.002s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.522s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.523s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.522s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.523s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.522s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.521s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.520s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.520s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.519s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.518s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.517s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.515s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.516s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.516s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.516s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.515s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.515s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.515s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.514s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.514s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.515s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.515s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.515s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.515s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.516s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.515s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.515s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.515s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.516s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.515s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.516s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.516s + 0.002s (eta: 0:01:01)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.515s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.516s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.516s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.516s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.517s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.517s + 0.002s (eta: 0:00:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.518s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.518s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.517s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.516s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.514s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step4999.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.582s + 0.002s (eta: 0:06:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.499s + 0.002s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.505s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.514s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.509s + 0.002s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.500s + 0.002s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.505s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.504s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.509s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.508s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.504s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.504s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.505s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.503s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.502s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.505s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.505s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.505s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.508s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.506s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.506s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.508s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.508s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.510s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.510s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.509s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.511s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.511s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.509s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.510s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.509s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.509s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.509s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.509s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.509s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.510s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.510s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.510s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.510s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.511s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.511s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.511s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.511s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.511s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.511s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.510s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.511s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.510s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.510s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.510s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.512s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.511s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.511s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.511s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.511s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.511s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.512s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.512s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.513s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.512s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.513s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.511s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 336.016s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [1725  258 1648 ...  230 1077 1306]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.8315
INFO voc_eval.py: 171: [1024  471  951 ...  280  126 1256]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8352
INFO voc_eval.py: 171: [1250 1336 1447 ... 1052  221  385]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.7917
INFO voc_eval.py: 171: [ 926 3188 2282 ... 3554 1278 1085]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6766
INFO voc_eval.py: 171: [1590 3306 1121 ... 2855 1843 2477]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.7087
INFO voc_eval.py: 171: [1235  177  894 ... 1590  266  214]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.8425
INFO voc_eval.py: 171: [3044 5927  447 ... 7155 1704  970]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8738
INFO voc_eval.py: 171: [1375  591  349 ... 1105  381  377]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8642
INFO voc_eval.py: 171: [ 212  211 4219 ... 8627 9249 4042]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6500
INFO voc_eval.py: 171: [ 674 1138 1398 ...   59  763 1420]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.8016
INFO voc_eval.py: 171: [1117 1519 2158 ... 2750 3504 3285]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.7088
INFO voc_eval.py: 171: [1165 1290  134 ... 1285 1620 1072]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8510
INFO voc_eval.py: 171: [ 141   30  466 ...  545 1071 1122]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8601
INFO voc_eval.py: 171: [ 532 1707  306 ...  724  160  412]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.8223
INFO voc_eval.py: 171: [ 6274  5643 17186 ...  3474 17394 14619]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8518
INFO voc_eval.py: 171: [4983 3969 3747 ... 2535   50  177]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.5231
INFO voc_eval.py: 171: [  69  494   55 ... 1320   90  584]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.7954
INFO voc_eval.py: 171: [ 384 1600 1059 ...   58 1549 1508]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7629
INFO voc_eval.py: 171: [1525  941  221 ...  977  464 1597]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.8389
INFO voc_eval.py: 171: [ 118  982  242 ... 1292   76  698]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7827
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7836
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.831
INFO voc_dataset_evaluator.py: 134: 0.835
INFO voc_dataset_evaluator.py: 134: 0.792
INFO voc_dataset_evaluator.py: 134: 0.677
INFO voc_dataset_evaluator.py: 134: 0.709
INFO voc_dataset_evaluator.py: 134: 0.842
INFO voc_dataset_evaluator.py: 134: 0.874
INFO voc_dataset_evaluator.py: 134: 0.864
INFO voc_dataset_evaluator.py: 134: 0.650
INFO voc_dataset_evaluator.py: 134: 0.802
INFO voc_dataset_evaluator.py: 134: 0.709
INFO voc_dataset_evaluator.py: 134: 0.851
INFO voc_dataset_evaluator.py: 134: 0.860
INFO voc_dataset_evaluator.py: 134: 0.822
INFO voc_dataset_evaluator.py: 134: 0.852
INFO voc_dataset_evaluator.py: 134: 0.523
INFO voc_dataset_evaluator.py: 134: 0.795
INFO voc_dataset_evaluator.py: 134: 0.763
INFO voc_dataset_evaluator.py: 134: 0.839
INFO voc_dataset_evaluator.py: 134: 0.783
INFO voc_dataset_evaluator.py: 135: 0.784
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
Start testing on iteration 7499
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.622s + 0.002s (eta: 0:06:25)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.560s + 0.003s (eta: 0:05:42)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.545s + 0.002s (eta: 0:05:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.528s + 0.002s (eta: 0:05:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.526s + 0.002s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.515s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.514s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.515s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.514s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.512s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.512s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.508s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.508s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.513s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.509s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.505s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.506s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.507s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.506s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.506s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.507s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.505s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.505s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.505s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.503s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.504s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.504s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.505s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.505s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.506s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.505s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.506s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.505s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.506s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.505s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.505s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.505s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.506s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.506s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.505s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.507s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.506s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.505s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.505s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.506s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.506s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.505s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.505s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.505s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.504s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.504s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.505s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.505s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.506s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.506s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.506s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.505s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.506s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.506s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.505s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.504s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.503s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.594s + 0.001s (eta: 0:06:07)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.536s + 0.002s (eta: 0:05:26)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.504s + 0.002s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.518s + 0.002s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.523s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.522s + 0.002s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.522s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.521s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.520s + 0.003s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.521s + 0.003s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.516s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.517s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.515s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.513s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.513s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.511s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.513s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.512s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.515s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.515s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.518s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.519s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.519s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.519s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.519s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.518s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.517s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.517s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.516s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.516s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.515s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.515s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.513s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.513s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.511s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.511s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.511s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.511s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.510s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.509s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.510s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.510s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.510s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.510s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.510s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.510s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.509s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.509s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.509s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.509s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.509s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.509s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.509s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.508s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.507s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.508s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.507s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.507s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.507s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.507s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.507s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.586s + 0.002s (eta: 0:06:03)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.518s + 0.002s (eta: 0:05:16)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.506s + 0.003s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.493s + 0.003s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.501s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.503s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.499s + 0.003s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.496s + 0.003s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.500s + 0.003s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.498s + 0.003s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.497s + 0.003s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.498s + 0.003s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.496s + 0.003s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.497s + 0.003s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.501s + 0.003s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.503s + 0.003s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.507s + 0.003s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.509s + 0.003s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.508s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.509s + 0.003s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.507s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.507s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.511s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.511s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.510s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.512s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.512s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.512s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.511s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.511s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.512s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.512s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.512s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.512s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.513s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.513s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.514s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.514s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.515s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.514s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.514s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.513s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.513s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.513s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.513s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.513s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.513s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.513s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.512s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.512s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.511s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.510s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.510s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.511s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.511s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.510s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.510s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.510s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.509s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.509s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.510s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.509s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.568s + 0.001s (eta: 0:05:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.496s + 0.001s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.506s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.517s + 0.002s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.511s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.506s + 0.001s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.509s + 0.001s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.510s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.510s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.509s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.510s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.510s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.508s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.507s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.502s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.501s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.500s + 0.002s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.500s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.499s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.500s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.500s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.498s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.498s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.497s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.496s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.496s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.497s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.497s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.496s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.497s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.497s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.496s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.496s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.496s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.496s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.497s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.496s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.496s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.496s + 0.002s (eta: 0:01:58)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.495s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.495s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.494s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.494s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.496s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.495s + 0.002s (eta: 0:01:28)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.495s + 0.002s (eta: 0:01:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.494s + 0.002s (eta: 0:01:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.494s + 0.002s (eta: 0:01:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.494s + 0.002s (eta: 0:01:08)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.494s + 0.002s (eta: 0:01:03)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.494s + 0.002s (eta: 0:00:58)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.494s + 0.002s (eta: 0:00:53)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.493s + 0.002s (eta: 0:00:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.494s + 0.002s (eta: 0:00:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.494s + 0.002s (eta: 0:00:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.494s + 0.002s (eta: 0:00:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.494s + 0.002s (eta: 0:00:28)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.494s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.494s + 0.002s (eta: 0:00:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.494s + 0.002s (eta: 0:00:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.494s + 0.002s (eta: 0:00:08)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.494s + 0.002s (eta: 0:00:03)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.655s + 0.001s (eta: 0:06:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.548s + 0.002s (eta: 0:05:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.552s + 0.002s (eta: 0:05:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.535s + 0.002s (eta: 0:05:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.526s + 0.003s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.520s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.514s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.513s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.520s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.516s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.515s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.517s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.512s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.512s + 0.002s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.513s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.509s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.508s + 0.002s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.507s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.507s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.504s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.504s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.503s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.501s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.503s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.501s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.499s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.498s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.496s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.497s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.496s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.495s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.494s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.494s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.496s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.495s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.496s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.496s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.496s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.496s + 0.002s (eta: 0:01:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.495s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.496s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.496s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.496s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.496s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.497s + 0.002s (eta: 0:01:28)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.497s + 0.002s (eta: 0:01:23)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.497s + 0.002s (eta: 0:01:18)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.499s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.499s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.500s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.500s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.500s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.501s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.501s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.502s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.501s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.501s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.501s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.502s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.501s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.501s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.502s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.647s + 0.002s (eta: 0:06:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.521s + 0.001s (eta: 0:05:17)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.523s + 0.002s (eta: 0:05:13)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.491s + 0.002s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.496s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.505s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.513s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.518s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.516s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.516s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.516s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.514s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.516s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.515s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.514s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.513s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.512s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.513s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.510s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.510s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.511s + 0.002s (eta: 0:03:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.512s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.511s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.511s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.510s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.510s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.512s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.511s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.511s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.510s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.509s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.508s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.508s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.505s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.504s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.505s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.505s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.506s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.506s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.506s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.507s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.507s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.508s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.509s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.509s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.508s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.509s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.509s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.509s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.509s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.509s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.509s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.510s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.510s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.509s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.509s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.510s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.510s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.510s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.510s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.510s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.509s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.556s + 0.001s (eta: 0:05:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.478s + 0.001s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.486s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.515s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.497s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.503s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.500s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.503s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.499s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.497s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.495s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.497s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.498s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.498s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.499s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.500s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.498s + 0.002s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.497s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.498s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.503s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.503s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.503s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.504s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.505s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.505s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.506s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.506s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.507s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.507s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.507s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.506s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.506s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.506s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.507s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.507s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.507s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.506s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.505s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.504s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.503s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.503s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.502s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.502s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.502s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.502s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.503s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.503s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.502s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.503s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.503s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.503s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.503s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.503s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.502s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.502s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.502s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.503s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.503s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.503s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.503s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.502s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.501s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step7499.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.676s + 0.002s (eta: 0:06:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.511s + 0.001s (eta: 0:05:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.510s + 0.002s (eta: 0:05:06)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.503s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.493s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.493s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.501s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.504s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.510s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.513s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.512s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.510s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.509s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.511s + 0.002s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.505s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.505s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.504s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.501s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.502s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.501s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.502s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.506s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.505s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.506s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.504s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.502s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.501s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.501s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.499s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.500s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.502s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.502s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.502s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.504s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.505s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.504s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.504s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.504s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.503s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.502s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.503s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.503s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.502s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.502s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.502s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.501s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.502s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.502s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.502s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.502s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.502s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.502s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.502s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.501s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.501s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.501s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.501s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.501s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.501s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.501s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.502s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.501s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 333.656s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [1765  257 1710 ... 1768 1194  983]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.8205
INFO voc_eval.py: 171: [1027  950 2106 ...  844 1390 1728]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8234
INFO voc_eval.py: 171: [1258 1446 1073 ... 1405  910 1814]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.7594
INFO voc_eval.py: 171: [2285  927 3210 ... 1759 2766 2835]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6778
INFO voc_eval.py: 171: [1599 3293 1109 ... 2240 3651  437]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.6943
INFO voc_eval.py: 171: [1182  569  136 ... 1393  379  292]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.8383
INFO voc_eval.py: 171: [4581 1536 5907 ... 3985 6200 3764]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8744
INFO voc_eval.py: 171: [ 364  611  340 ...  291 1236  825]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8529
INFO voc_eval.py: 171: [ 218  217 5644 ... 6090 5232 8385]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6440
INFO voc_eval.py: 171: [1114  654  461 ... 1289  303  409]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.7974
INFO voc_eval.py: 171: [1064 1436 3004 ... 2317  213 2173]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.6997
INFO voc_eval.py: 171: [1151  138 1270 ... 1866 1361  234]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8455
INFO voc_eval.py: 171: [  29  142  118 ...  145 1222 1076]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8447
INFO voc_eval.py: 171: [ 561 1779  324 ... 1797 1649 1416]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.8201
INFO voc_eval.py: 171: [ 8346 17375 10162 ...  1860 10220 10825]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8476
INFO voc_eval.py: 171: [  32 4729 3766 ... 4186 1410 4194]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.5188
INFO voc_eval.py: 171: [ 506   74  490 ...  727  413 1223]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.7889
INFO voc_eval.py: 171: [ 403 1107  654 ...  622 2086 1894]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7566
INFO voc_eval.py: 171: [1055  224 1527 ...  177  403  455]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.8288
INFO voc_eval.py: 171: [ 122  972  241 ...  558 1391  163]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7633
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7748
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.821
INFO voc_dataset_evaluator.py: 134: 0.823
INFO voc_dataset_evaluator.py: 134: 0.759
INFO voc_dataset_evaluator.py: 134: 0.678
INFO voc_dataset_evaluator.py: 134: 0.694
INFO voc_dataset_evaluator.py: 134: 0.838
INFO voc_dataset_evaluator.py: 134: 0.874
INFO voc_dataset_evaluator.py: 134: 0.853
INFO voc_dataset_evaluator.py: 134: 0.644
INFO voc_dataset_evaluator.py: 134: 0.797
INFO voc_dataset_evaluator.py: 134: 0.700
INFO voc_dataset_evaluator.py: 134: 0.845
INFO voc_dataset_evaluator.py: 134: 0.845
INFO voc_dataset_evaluator.py: 134: 0.820
INFO voc_dataset_evaluator.py: 134: 0.848
INFO voc_dataset_evaluator.py: 134: 0.519
INFO voc_dataset_evaluator.py: 134: 0.789
INFO voc_dataset_evaluator.py: 134: 0.757
INFO voc_dataset_evaluator.py: 134: 0.829
INFO voc_dataset_evaluator.py: 134: 0.763
INFO voc_dataset_evaluator.py: 135: 0.775
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
Start testing on iteration 9999
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.12s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.431s + 0.001s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.444s + 0.001s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.480s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.498s + 0.002s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.489s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.497s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.500s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.496s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.493s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.495s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.495s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.496s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.496s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.497s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.498s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.497s + 0.002s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.498s + 0.002s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.498s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.500s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.502s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.503s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.503s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.503s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.505s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.505s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.507s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.506s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.507s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.506s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.507s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.507s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.507s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.505s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.504s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.503s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.503s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.503s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.503s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.504s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.505s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.504s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.505s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.504s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.503s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.504s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.503s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.503s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.504s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.504s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.503s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.502s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.501s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.500s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.500s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.500s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.500s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.500s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.500s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.500s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.501s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.501s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.501s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.540s + 0.002s (eta: 0:05:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.494s + 0.002s (eta: 0:05:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.485s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.512s + 0.002s (eta: 0:05:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.511s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.515s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.500s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.495s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.499s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.496s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.493s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.492s + 0.002s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.498s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.498s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.499s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.501s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.500s + 0.002s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.500s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.500s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.497s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.498s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.501s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.502s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.504s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.506s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.503s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.504s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.505s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.505s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.506s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.506s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.506s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.506s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.505s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.506s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.506s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.506s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.506s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.506s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.505s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.505s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.505s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.505s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.505s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.504s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.504s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.504s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.504s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.504s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.505s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.505s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.505s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.504s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.504s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.503s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.503s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.502s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.502s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.502s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.501s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.502s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.501s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.561s + 0.001s (eta: 0:05:47)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.485s + 0.002s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.505s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.504s + 0.002s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.495s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.499s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.504s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.509s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.516s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.519s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.519s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.516s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.517s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.518s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.520s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.522s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.521s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.523s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.520s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.520s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.516s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.518s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.518s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.517s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.518s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.517s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.516s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.516s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.514s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.514s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.511s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.511s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.511s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.511s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.510s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.509s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.510s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.508s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.507s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.507s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.508s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.508s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.509s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.509s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.509s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.510s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.508s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.509s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.509s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.510s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.510s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.510s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.511s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.511s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.510s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.511s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.510s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.510s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.509s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.509s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.509s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.508s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.798s + 0.001s (eta: 0:08:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.553s + 0.001s (eta: 0:05:37)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.510s + 0.001s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.512s + 0.001s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.508s + 0.002s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.505s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.507s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.505s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.504s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.507s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.505s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.507s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.506s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.508s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.508s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.508s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.505s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.504s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.503s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.505s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.507s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.507s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.506s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.507s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.508s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.507s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.507s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.507s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.507s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.507s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.508s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.507s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.508s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.506s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.507s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.506s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.507s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.506s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.505s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.504s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.504s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.504s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.504s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.504s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.503s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.502s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.502s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.502s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.502s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.500s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.501s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.501s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.501s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.501s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.501s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.501s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.501s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.500s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.501s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.502s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.501s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.502s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.484s + 0.002s (eta: 0:04:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.471s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.496s + 0.002s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.489s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.498s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.495s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.492s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.493s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.502s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.498s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.498s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.502s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.506s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.502s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.502s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.502s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.500s + 0.003s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.500s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.499s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.503s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.504s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.502s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.504s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.507s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.508s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.511s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.509s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.508s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.508s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.507s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.507s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.506s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.506s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.507s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.507s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.508s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.508s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.508s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.508s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.508s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.508s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.508s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.507s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.507s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.507s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.506s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.506s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.506s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.506s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.506s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.505s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.505s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.505s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.505s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.504s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.504s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.504s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.505s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.504s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.504s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.504s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.504s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.876s + 0.002s (eta: 0:09:02)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.528s + 0.002s (eta: 0:05:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.509s + 0.002s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.501s + 0.002s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.494s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.492s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.497s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.507s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.503s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.504s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.510s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.512s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.512s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.513s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.517s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.518s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.517s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.516s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.516s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.516s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.514s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.516s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.516s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.516s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.516s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.517s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.518s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.518s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.517s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.517s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.518s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.517s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.517s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.516s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.515s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.515s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.515s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.515s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.516s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.516s + 0.002s (eta: 0:01:58)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.516s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.517s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.517s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.517s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.516s + 0.002s (eta: 0:01:32)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.516s + 0.002s (eta: 0:01:27)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.516s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.516s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.516s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.515s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.515s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.515s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.516s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.516s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.515s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.515s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.515s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.515s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.515s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.515s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.514s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.512s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.606s + 0.002s (eta: 0:06:15)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.526s + 0.002s (eta: 0:05:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.529s + 0.002s (eta: 0:05:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.528s + 0.002s (eta: 0:05:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.508s + 0.003s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.510s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.511s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.516s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.520s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.518s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.520s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.520s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.518s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.513s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.513s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.513s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.513s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.513s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.513s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.513s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.515s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.514s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.514s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.512s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.511s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.514s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.516s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.516s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.515s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.515s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.514s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.512s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.513s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.514s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.515s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.513s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.514s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.513s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.513s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.514s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.512s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.513s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.513s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.514s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.514s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.512s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.512s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.512s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.512s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.511s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.511s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.510s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.510s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.509s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.509s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.509s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.509s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.509s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.509s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.508s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step9999.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.983s + 0.002s (eta: 0:10:08)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.555s + 0.001s (eta: 0:05:38)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.532s + 0.001s (eta: 0:05:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.539s + 0.001s (eta: 0:05:17)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.524s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.519s + 0.002s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.516s + 0.003s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.517s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.514s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.513s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.512s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.509s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.503s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.505s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.501s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.502s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.504s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.504s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.502s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.503s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.502s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.503s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.502s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.501s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.501s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.500s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.500s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.500s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.498s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.498s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.498s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.497s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.499s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.499s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.498s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.498s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.499s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.499s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.498s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.498s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.498s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.497s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.498s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.498s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.498s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.497s + 0.002s (eta: 0:01:23)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.498s + 0.002s (eta: 0:01:18)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.497s + 0.002s (eta: 0:01:13)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.497s + 0.002s (eta: 0:01:08)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.498s + 0.002s (eta: 0:01:03)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.498s + 0.002s (eta: 0:00:58)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.499s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.499s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.498s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.498s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.498s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.498s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.498s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.498s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.498s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.499s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.499s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 332.539s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [1780 1731 1701 ...  291  751  112]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.8218
INFO voc_eval.py: 171: [1336 2086  940 ... 1975 1352 2060]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8204
INFO voc_eval.py: 171: [1095  889 1453 ... 1364  162 1089]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.7507
INFO voc_eval.py: 171: [2197  898  119 ... 2806  501  618]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6567
INFO voc_eval.py: 171: [1560 3143 2962 ... 3180 3667 1111]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.6853
INFO voc_eval.py: 171: [ 850 1149  566 ...  921 1123   22]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.8226
INFO voc_eval.py: 171: [4658 4591 1528 ... 3658 7103 1622]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8720
INFO voc_eval.py: 171: [ 628  938 1058 ...  398  532  207]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8416
INFO voc_eval.py: 171: [ 205  204 5410 ... 4818 3297 7048]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6376
INFO voc_eval.py: 171: [1067  637  434 ...  446  181 1398]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.7915
INFO voc_eval.py: 171: [ 947 2707  571 ... 2090 1424  615]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.7000
INFO voc_eval.py: 171: [ 135 1272  876 ... 1596 1478  585]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8369
INFO voc_eval.py: 171: [ 36 145 486 ... 552 869 315]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8311
INFO voc_eval.py: 171: [ 577 1832  317 ...  922 1573  324]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.8073
INFO voc_eval.py: 171: [ 7283  6615  9400 ...   973 16914 10415]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8417
INFO voc_eval.py: 171: [3425 3321   31 ...  620  570 1757]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.4963
INFO voc_eval.py: 171: [  65  503 1357 ... 1115  306  831]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.7757
INFO voc_eval.py: 171: [1078  398  632 ... 1893  685  204]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7539
INFO voc_eval.py: 171: [ 225 1027  922 ...  427 1204 1070]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.8130
INFO voc_eval.py: 171: [ 943  234  123 ...  242  977 1052]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7569
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7657
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.822
INFO voc_dataset_evaluator.py: 134: 0.820
INFO voc_dataset_evaluator.py: 134: 0.751
INFO voc_dataset_evaluator.py: 134: 0.657
INFO voc_dataset_evaluator.py: 134: 0.685
INFO voc_dataset_evaluator.py: 134: 0.823
INFO voc_dataset_evaluator.py: 134: 0.872
INFO voc_dataset_evaluator.py: 134: 0.842
INFO voc_dataset_evaluator.py: 134: 0.638
INFO voc_dataset_evaluator.py: 134: 0.792
INFO voc_dataset_evaluator.py: 134: 0.700
INFO voc_dataset_evaluator.py: 134: 0.837
INFO voc_dataset_evaluator.py: 134: 0.831
INFO voc_dataset_evaluator.py: 134: 0.807
INFO voc_dataset_evaluator.py: 134: 0.842
INFO voc_dataset_evaluator.py: 134: 0.496
INFO voc_dataset_evaluator.py: 134: 0.776
INFO voc_dataset_evaluator.py: 134: 0.754
INFO voc_dataset_evaluator.py: 134: 0.813
INFO voc_dataset_evaluator.py: 134: 0.757
INFO voc_dataset_evaluator.py: 135: 0.766
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
Start testing on iteration 12499
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.939s + 0.014s (eta: 0:09:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.538s + 0.004s (eta: 0:05:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.544s + 0.004s (eta: 0:05:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.526s + 0.003s (eta: 0:05:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.539s + 0.003s (eta: 0:05:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.533s + 0.003s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.530s + 0.003s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.524s + 0.003s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.517s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.517s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.513s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.513s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.514s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.513s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.512s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.513s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.514s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.512s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.514s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.516s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.516s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.516s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.514s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.514s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.515s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.514s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.514s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.512s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.513s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.513s + 0.003s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.512s + 0.003s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.512s + 0.003s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.510s + 0.003s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.509s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.509s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.509s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.509s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.509s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.508s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.508s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.507s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.508s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.508s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.508s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.508s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.508s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.508s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.507s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.507s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.507s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.507s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.507s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.508s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.507s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.507s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.506s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.507s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.507s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.506s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.506s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.507s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.506s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.590s + 0.001s (eta: 0:06:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.485s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.487s + 0.004s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.507s + 0.003s (eta: 0:04:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.514s + 0.003s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.513s + 0.003s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.507s + 0.003s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.502s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.500s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.498s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.500s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.500s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.497s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.498s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.498s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.498s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.496s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.495s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.494s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.494s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.494s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.495s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.494s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.496s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.495s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.497s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.497s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.496s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.497s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.496s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.497s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.497s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.497s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.498s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.498s + 0.002s (eta: 0:02:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.500s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.500s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.500s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.500s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.501s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.502s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.502s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.501s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.501s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.502s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.502s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.502s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.503s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.504s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.503s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.502s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.502s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.502s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.502s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.502s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.502s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.501s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.501s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.502s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.502s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.501s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.501s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.607s + 0.001s (eta: 0:06:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.503s + 0.001s (eta: 0:05:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.520s + 0.002s (eta: 0:05:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.525s + 0.002s (eta: 0:05:10)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.517s + 0.002s (eta: 0:04:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.509s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.503s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.499s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.501s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.506s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.506s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.502s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.505s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.505s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.503s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.503s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.506s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.507s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.505s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.506s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.506s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.504s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.505s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.505s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.504s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.504s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.505s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.505s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.505s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.504s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.505s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.505s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.505s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.504s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.505s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.505s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.505s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.505s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.504s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.503s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.504s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.504s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.503s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.503s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.504s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.503s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.502s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.502s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.501s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.501s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.501s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.501s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.501s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.503s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.502s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.501s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.501s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.500s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.499s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.499s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.500s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.499s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.601s + 0.003s (eta: 0:06:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.546s + 0.002s (eta: 0:05:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.518s + 0.003s (eta: 0:05:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.511s + 0.002s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.513s + 0.002s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.511s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.506s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.505s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.507s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.504s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.506s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.506s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.504s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.505s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.504s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.501s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.504s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.504s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.502s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.501s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.501s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.503s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.503s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.505s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.506s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.506s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.505s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.505s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.505s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.504s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.504s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.505s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.505s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.507s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.506s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.507s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.507s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.507s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.508s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.508s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.508s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.508s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.508s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.508s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.508s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.508s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.508s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.508s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.508s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.507s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.508s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.507s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.507s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.507s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.507s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.507s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.507s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.507s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.507s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.507s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.507s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.507s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.591s + 0.001s (eta: 0:06:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.480s + 0.001s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.490s + 0.001s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.484s + 0.002s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.480s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.488s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.495s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.489s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.495s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.493s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.489s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.490s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.491s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.490s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.491s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.492s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.495s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.494s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.493s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.492s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.492s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.493s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.494s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.495s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.496s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.498s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.495s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.494s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.494s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.494s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.493s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.493s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.495s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.494s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.495s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.497s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.497s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.497s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.497s + 0.002s (eta: 0:01:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.498s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.498s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.498s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.497s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.497s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.497s + 0.002s (eta: 0:01:28)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.497s + 0.002s (eta: 0:01:23)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.497s + 0.002s (eta: 0:01:18)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.497s + 0.002s (eta: 0:01:13)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.497s + 0.002s (eta: 0:01:08)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.497s + 0.002s (eta: 0:01:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.497s + 0.002s (eta: 0:00:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.497s + 0.002s (eta: 0:00:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.498s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.498s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.497s + 0.002s (eta: 0:00:38)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.497s + 0.002s (eta: 0:00:33)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.498s + 0.002s (eta: 0:00:28)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.497s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.497s + 0.002s (eta: 0:00:18)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.498s + 0.002s (eta: 0:00:13)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.497s + 0.002s (eta: 0:00:08)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.497s + 0.002s (eta: 0:00:03)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.634s + 0.002s (eta: 0:06:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.486s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.506s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.494s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.500s + 0.003s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.500s + 0.003s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.498s + 0.003s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.499s + 0.003s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.497s + 0.003s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.499s + 0.003s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.503s + 0.003s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.502s + 0.003s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.504s + 0.003s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.500s + 0.003s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.502s + 0.003s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.505s + 0.003s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.506s + 0.003s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.508s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.507s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.507s + 0.003s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.507s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.508s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.509s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.507s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.506s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.505s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.504s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.502s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.502s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.502s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.502s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.501s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.500s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.500s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.500s + 0.002s (eta: 0:02:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.502s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.501s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.502s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.502s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.502s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.503s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.504s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.504s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.506s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.506s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.505s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.505s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.505s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.504s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.503s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.503s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.503s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.503s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.503s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.502s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.502s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.502s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.502s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.502s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.503s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.503s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.502s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.818s + 0.001s (eta: 0:08:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.512s + 0.001s (eta: 0:05:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.508s + 0.002s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.503s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.505s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.501s + 0.002s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.499s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.499s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.491s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.494s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.493s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.495s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.493s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.492s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.493s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.495s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.498s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.500s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.502s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.503s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.503s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.504s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.501s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.501s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.499s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.499s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.500s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.500s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.500s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.501s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.499s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.500s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.500s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.500s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.500s + 0.002s (eta: 0:02:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.500s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.501s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.500s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.501s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.502s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.501s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.501s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.501s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.502s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.502s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.502s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.503s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.504s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.504s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.504s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.503s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.503s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.504s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.504s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.504s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.504s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.504s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.504s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.504s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.504s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.504s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.505s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step12499.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.659s + 0.002s (eta: 0:06:48)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.538s + 0.002s (eta: 0:05:28)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.549s + 0.001s (eta: 0:05:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.533s + 0.001s (eta: 0:05:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.530s + 0.002s (eta: 0:05:07)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.520s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.529s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.529s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.525s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.526s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.520s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.515s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.515s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.515s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.515s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.514s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.510s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.508s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.510s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.509s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.509s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.508s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.507s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.508s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.506s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.504s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.502s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.503s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.504s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.503s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.503s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.503s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.503s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.503s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.502s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.502s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.504s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.504s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.505s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.505s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.505s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.505s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.504s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.505s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.503s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.502s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.502s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.503s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.503s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.504s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.504s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.504s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.503s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.503s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.503s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.502s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.502s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.502s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.502s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.502s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.503s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.502s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 332.440s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [1875 1824 1109 ... 1795 1846 1701]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.7980
INFO voc_eval.py: 171: [ 969 1369  488 ... 1978 1587 1031]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8171
INFO voc_eval.py: 171: [ 924 1501 1135 ...  278  203 1109]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.7360
INFO voc_eval.py: 171: [2275  125 3207 ... 1474 2904 1943]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6572
INFO voc_eval.py: 171: [1554 3124 2934 ... 2998 2093 2462]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.6651
INFO voc_eval.py: 171: [ 566 1516  142 ...  429 1586 1581]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.8119
INFO voc_eval.py: 171: [2657 3729 7511 ...  107 3719 4834]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8667
INFO voc_eval.py: 171: [ 967  647 1091 ...  511  137 1007]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8345
INFO voc_eval.py: 171: [ 221  222 5541 ... 3269 4756 6599]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6247
INFO voc_eval.py: 171: [1141  679  331 ... 1438  134 1477]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.7879
INFO voc_eval.py: 171: [ 962 2662  572 ...  700  639 1631]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.6845
INFO voc_eval.py: 171: [ 130 1276  530 ...  500 1203  465]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8220
INFO voc_eval.py: 171: [  41  158  517 ... 1389  489  304]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8292
INFO voc_eval.py: 171: [ 580 1853  319 ... 1409  599  432]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.8063
INFO voc_eval.py: 171: [22856  6863 10810 ... 10183  1656  9667]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8357
INFO voc_eval.py: 171: [1580   29 3272 ... 1774  616 4453]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.4844
INFO voc_eval.py: 171: [ 540   72 1206 ...  575  201 1142]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.7624
INFO voc_eval.py: 171: [1120 1660  415 ...  946  940 2161]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7343
INFO voc_eval.py: 171: [ 225   89 1059 ...  691  296 1674]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.8074
INFO voc_eval.py: 171: [ 910  229  528 ...  777 1486 1340]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7404
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7553
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.798
INFO voc_dataset_evaluator.py: 134: 0.817
INFO voc_dataset_evaluator.py: 134: 0.736
INFO voc_dataset_evaluator.py: 134: 0.657
INFO voc_dataset_evaluator.py: 134: 0.665
INFO voc_dataset_evaluator.py: 134: 0.812
INFO voc_dataset_evaluator.py: 134: 0.867
INFO voc_dataset_evaluator.py: 134: 0.834
INFO voc_dataset_evaluator.py: 134: 0.625
INFO voc_dataset_evaluator.py: 134: 0.788
INFO voc_dataset_evaluator.py: 134: 0.684
INFO voc_dataset_evaluator.py: 134: 0.822
INFO voc_dataset_evaluator.py: 134: 0.829
INFO voc_dataset_evaluator.py: 134: 0.806
INFO voc_dataset_evaluator.py: 134: 0.836
INFO voc_dataset_evaluator.py: 134: 0.484
INFO voc_dataset_evaluator.py: 134: 0.762
INFO voc_dataset_evaluator.py: 134: 0.734
INFO voc_dataset_evaluator.py: 134: 0.807
INFO voc_dataset_evaluator.py: 134: 0.740
INFO voc_dataset_evaluator.py: 135: 0.755
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
Start testing on iteration 14999
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.900s + 0.002s (eta: 0:09:17)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.566s + 0.005s (eta: 0:05:47)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.536s + 0.006s (eta: 0:05:23)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.537s + 0.004s (eta: 0:05:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.540s + 0.004s (eta: 0:05:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.543s + 0.004s (eta: 0:05:10)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.536s + 0.003s (eta: 0:05:01)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.532s + 0.003s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.529s + 0.004s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.528s + 0.003s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.521s + 0.003s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.522s + 0.003s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.524s + 0.003s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.524s + 0.003s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.520s + 0.003s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.518s + 0.003s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.517s + 0.003s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.517s + 0.003s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.519s + 0.003s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.519s + 0.003s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.519s + 0.003s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.516s + 0.003s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.515s + 0.003s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.516s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.516s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.517s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.517s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.515s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.516s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.516s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.514s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.515s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.515s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.516s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.516s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.516s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.516s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.515s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.514s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.514s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.515s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.515s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.514s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.514s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.514s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.514s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.515s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.514s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.514s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.514s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.514s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.514s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.514s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.514s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.515s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.515s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.515s + 0.002s (eta: 0:00:30)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.515s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.515s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.515s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.514s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.514s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.11s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.573s + 0.001s (eta: 0:05:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.520s + 0.002s (eta: 0:05:16)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.499s + 0.002s (eta: 0:04:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.493s + 0.001s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.501s + 0.001s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.500s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.507s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.511s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.514s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.509s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.509s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.508s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.508s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.513s + 0.002s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.511s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.512s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.514s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.513s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.510s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.510s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.511s + 0.002s (eta: 0:03:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.513s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.514s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.514s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.512s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.511s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.512s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.514s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.514s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.513s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.515s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.515s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.515s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.515s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.514s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.513s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.515s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.515s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.515s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.515s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.514s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.515s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.515s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.514s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.514s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.514s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.513s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.512s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.512s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.512s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.511s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.511s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.511s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.510s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.510s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.509s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.508s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.509s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.509s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.507s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.701s + 0.002s (eta: 0:07:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.557s + 0.003s (eta: 0:05:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.529s + 0.003s (eta: 0:05:18)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.520s + 0.003s (eta: 0:05:07)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.529s + 0.003s (eta: 0:05:07)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.529s + 0.003s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.524s + 0.003s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.531s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.528s + 0.003s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.526s + 0.003s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.522s + 0.003s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.523s + 0.003s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.523s + 0.003s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.520s + 0.003s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.524s + 0.003s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.524s + 0.003s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.523s + 0.003s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.524s + 0.003s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.525s + 0.003s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.522s + 0.003s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.519s + 0.003s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.518s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.519s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.517s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.516s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.515s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.516s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.515s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.514s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.515s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.515s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.516s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.515s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.514s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.514s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.514s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.513s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.513s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.514s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.513s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.512s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.511s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.511s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.513s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.514s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.514s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.514s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.514s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.514s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.514s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.515s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.515s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.515s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.514s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.515s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.515s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.515s + 0.002s (eta: 0:00:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.515s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.515s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.515s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.514s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.514s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.572s + 0.001s (eta: 0:05:53)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.514s + 0.002s (eta: 0:05:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.485s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.495s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.494s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.498s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.502s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.503s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.499s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.502s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.504s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.505s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.504s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.508s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.508s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.505s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.506s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.507s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.506s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.507s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.508s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.509s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.509s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.511s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.510s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.509s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.507s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.505s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.506s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.506s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.507s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.507s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.508s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.508s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.507s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.508s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.508s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.509s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.509s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.509s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.508s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.508s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.507s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.508s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.507s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.507s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.506s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.506s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.505s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.505s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.504s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.504s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.505s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.504s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.504s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.504s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.504s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.504s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.504s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.504s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.503s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.504s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.848s + 0.001s (eta: 0:08:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.512s + 0.002s (eta: 0:05:11)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.538s + 0.002s (eta: 0:05:22)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.534s + 0.002s (eta: 0:05:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.530s + 0.002s (eta: 0:05:07)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.512s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.516s + 0.002s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.516s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.514s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.510s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.512s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.509s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.509s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.509s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.507s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.509s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.508s + 0.002s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.505s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.504s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.503s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.504s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.506s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.507s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.507s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.507s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.506s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.506s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.506s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.508s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.506s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.505s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.505s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.504s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.502s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.502s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.502s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.502s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.502s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.502s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.502s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.503s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.503s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.503s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.504s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.504s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.504s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.504s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.504s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.505s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.505s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.506s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.506s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.506s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.505s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.506s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.506s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.505s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.505s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.505s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.504s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.504s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.505s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.646s + 0.002s (eta: 0:06:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.518s + 0.002s (eta: 0:05:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.500s + 0.001s (eta: 0:04:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.500s + 0.001s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.494s + 0.001s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.501s + 0.001s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.507s + 0.001s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.507s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.507s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.507s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.511s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.510s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.511s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.508s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.510s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.512s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.512s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.514s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.514s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.512s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.511s + 0.002s (eta: 0:03:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.511s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.512s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.510s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.511s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.512s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.512s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.510s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.510s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.511s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.510s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.511s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.511s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.510s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.508s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.509s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.510s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.510s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.510s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.509s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.510s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.510s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.510s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.510s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.509s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.509s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.508s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.508s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.507s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.507s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.507s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.507s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.508s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.509s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.509s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.509s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.509s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.509s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.509s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.508s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.637s + 0.001s (eta: 0:06:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.548s + 0.001s (eta: 0:05:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.537s + 0.002s (eta: 0:05:22)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.544s + 0.002s (eta: 0:05:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.534s + 0.002s (eta: 0:05:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.526s + 0.002s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.515s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.515s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.517s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.520s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.520s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.520s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.519s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.518s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.517s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.518s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.517s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.515s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.515s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.514s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.515s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.514s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.514s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.512s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.513s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.512s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.513s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.515s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.515s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.514s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.512s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.512s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.514s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.515s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.515s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.516s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.515s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.515s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.514s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.514s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.515s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.514s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.514s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.515s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.516s + 0.002s (eta: 0:01:32)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.516s + 0.002s (eta: 0:01:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.515s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.515s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.515s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.515s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.514s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.514s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.514s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.513s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.513s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.513s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.513s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.514s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.514s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.514s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.515s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.514s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step14999.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.662s + 0.003s (eta: 0:06:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.547s + 0.003s (eta: 0:05:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.541s + 0.003s (eta: 0:05:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.535s + 0.003s (eta: 0:05:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.517s + 0.002s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.516s + 0.002s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.514s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.512s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.506s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.506s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.505s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.504s + 0.003s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.505s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.506s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.504s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.503s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.503s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.503s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.504s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.502s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.503s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.506s + 0.003s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.506s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.507s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.508s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.506s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.507s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.506s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.506s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.505s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.505s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.503s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.504s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.503s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.504s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.505s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.507s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.505s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.505s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.505s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.506s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.507s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.506s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.506s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.506s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.506s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.506s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.506s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.507s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.507s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.508s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.507s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.508s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.508s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.509s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.510s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.509s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.510s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.510s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.510s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.510s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.511s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 337.094s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [1843 1797 1090 ...  828 1827 1171]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.8006
INFO voc_eval.py: 171: [ 974 1379  314 ...  362  572 1774]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8134
INFO voc_eval.py: 171: [ 921 1496 1329 ... 1014 1758 1615]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.7297
INFO voc_eval.py: 171: [2221  118 3142 ... 3319 3506 2113]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6550
INFO voc_eval.py: 171: [1533  234 2884 ...  153 2006  795]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.6575
INFO voc_eval.py: 171: [ 571 1487  851 ... 1545 1479  624]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.8088
INFO voc_eval.py: 171: [4900 7495 3725 ... 3420 5854 1387]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8650
INFO voc_eval.py: 171: [ 663   80  363 ... 1023  154 1215]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8291
INFO voc_eval.py: 171: [ 225  226 5446 ... 9276 9807 6830]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6209
INFO voc_eval.py: 171: [1131  673  312 ...  767  986  687]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.7824
INFO voc_eval.py: 171: [ 931 1236  438 ... 1551  352 3076]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.6927
INFO voc_eval.py: 171: [ 134 1293  887 ... 1103 1847 1419]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8180
INFO voc_eval.py: 171: [  40  153  519 ...  310  919 1152]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8200
INFO voc_eval.py: 171: [ 585  319 1876 ... 1017  834 1276]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.8029
INFO voc_eval.py: 171: [22877 10838  6889 ...  7537 12824 20977]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8322
INFO voc_eval.py: 171: [4048 1694 3177 ...  503 3832 3503]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.4753
INFO voc_eval.py: 171: [ 529   72 1435 ...  787  220  603]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.7513
INFO voc_eval.py: 171: [1107 1632  411 ... 1404  951  978]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7336
INFO voc_eval.py: 171: [ 215   80 1050 ... 1152    4  674]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.7975
INFO voc_eval.py: 171: [889 575 230 ... 979 379 532]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7346
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7510
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.801
INFO voc_dataset_evaluator.py: 134: 0.813
INFO voc_dataset_evaluator.py: 134: 0.730
INFO voc_dataset_evaluator.py: 134: 0.655
INFO voc_dataset_evaluator.py: 134: 0.657
INFO voc_dataset_evaluator.py: 134: 0.809
INFO voc_dataset_evaluator.py: 134: 0.865
INFO voc_dataset_evaluator.py: 134: 0.829
INFO voc_dataset_evaluator.py: 134: 0.621
INFO voc_dataset_evaluator.py: 134: 0.782
INFO voc_dataset_evaluator.py: 134: 0.693
INFO voc_dataset_evaluator.py: 134: 0.818
INFO voc_dataset_evaluator.py: 134: 0.820
INFO voc_dataset_evaluator.py: 134: 0.803
INFO voc_dataset_evaluator.py: 134: 0.832
INFO voc_dataset_evaluator.py: 134: 0.475
INFO voc_dataset_evaluator.py: 134: 0.751
INFO voc_dataset_evaluator.py: 134: 0.734
INFO voc_dataset_evaluator.py: 134: 0.798
INFO voc_dataset_evaluator.py: 134: 0.735
INFO voc_dataset_evaluator.py: 135: 0.751
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
Start testing on iteration 17499
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.644s + 0.016s (eta: 0:06:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.534s + 0.003s (eta: 0:05:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.498s + 0.004s (eta: 0:04:59)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.489s + 0.003s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.494s + 0.003s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.504s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.504s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.500s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.506s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.505s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.506s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.507s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.510s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.508s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.507s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.507s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.506s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.507s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.508s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.510s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.512s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.512s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.511s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.512s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.513s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.513s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.511s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.510s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.510s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.510s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.509s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.510s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.509s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.509s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.510s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.510s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.509s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.509s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.511s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.511s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.510s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.511s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.512s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.511s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.510s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.511s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.510s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.509s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.509s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.509s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.509s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.508s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.508s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.508s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.507s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.508s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.508s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.507s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.507s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.507s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.507s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.507s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.605s + 0.001s (eta: 0:06:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.537s + 0.002s (eta: 0:05:27)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.535s + 0.002s (eta: 0:05:21)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.535s + 0.002s (eta: 0:05:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.528s + 0.002s (eta: 0:05:06)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.528s + 0.002s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.532s + 0.002s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.536s + 0.002s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.528s + 0.002s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.524s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.523s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.523s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.522s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.523s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.526s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.526s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.526s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.524s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.523s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.522s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.521s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.519s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.519s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.520s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.518s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.517s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.517s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.519s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.517s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.517s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.517s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.517s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.516s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.515s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.514s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.513s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.513s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.512s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.512s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.512s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.512s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.512s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.512s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.511s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.511s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.510s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.510s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.510s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.510s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.510s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.509s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.509s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.509s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.509s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.509s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.509s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.509s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.509s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.508s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.508s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.613s + 0.001s (eta: 0:06:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.511s + 0.002s (eta: 0:05:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.499s + 0.002s (eta: 0:04:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.507s + 0.002s (eta: 0:04:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.511s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.512s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.512s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.512s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.515s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.515s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.514s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.510s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.508s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.507s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.508s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.506s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.506s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.504s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.505s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.505s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.503s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.502s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.503s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.504s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.503s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.503s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.502s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.502s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.502s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.502s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.504s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.505s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.504s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.505s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.503s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.502s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.503s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.503s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.503s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.502s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.502s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.502s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.501s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.502s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.501s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.501s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.501s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.500s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.500s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.500s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.500s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.499s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.499s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.499s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.499s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.499s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.499s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.499s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.499s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.499s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.499s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.499s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.604s + 0.002s (eta: 0:06:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.501s + 0.001s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.486s + 0.001s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.494s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.491s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.493s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.493s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.500s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.497s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.499s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.500s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.497s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.495s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.492s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.494s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.496s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.496s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.497s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.497s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.498s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.499s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.500s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.497s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.498s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.499s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.499s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.499s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.499s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.500s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.499s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.500s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.500s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.500s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.501s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.502s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.503s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.503s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.502s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.503s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.501s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.502s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.501s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.501s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.501s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.502s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.502s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.502s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.503s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.505s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.504s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.504s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.504s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.505s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.504s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.505s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.505s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.505s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.505s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.505s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.506s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.506s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.506s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.11s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.586s + 0.001s (eta: 0:06:02)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.509s + 0.001s (eta: 0:05:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.546s + 0.002s (eta: 0:05:27)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.549s + 0.002s (eta: 0:05:23)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.531s + 0.003s (eta: 0:05:08)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.520s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.518s + 0.003s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.513s + 0.003s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.512s + 0.003s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.515s + 0.003s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.512s + 0.003s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.512s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.513s + 0.003s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.510s + 0.003s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.509s + 0.003s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.508s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.506s + 0.002s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.505s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.504s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.503s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.503s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.504s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.504s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.503s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.504s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.504s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.504s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.504s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.504s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.504s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.504s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.505s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.505s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.504s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.505s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.505s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.505s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.504s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.504s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.504s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.503s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.503s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.501s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.502s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.503s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.502s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.502s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.502s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.503s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.503s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.503s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.503s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.504s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.504s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.504s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.504s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.504s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.504s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.504s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.504s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.504s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.504s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.11s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.578s + 0.001s (eta: 0:05:57)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.467s + 0.003s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.497s + 0.003s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.494s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.501s + 0.003s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.499s + 0.002s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.508s + 0.003s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.509s + 0.003s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.513s + 0.003s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.514s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.514s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.515s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.517s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.515s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.515s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.517s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.513s + 0.003s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.513s + 0.003s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.513s + 0.003s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.513s + 0.003s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.512s + 0.003s (eta: 0:03:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.510s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.512s + 0.003s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.512s + 0.003s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.510s + 0.003s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.510s + 0.003s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.512s + 0.003s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.512s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.512s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.512s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.511s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.511s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.510s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.509s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.508s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.508s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.510s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.511s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.511s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.511s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.512s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.513s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.512s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.512s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.512s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.512s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.512s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.512s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.512s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.513s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.514s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.513s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.513s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.513s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.513s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.512s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.512s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.512s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.512s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.512s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.512s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.511s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.633s + 0.001s (eta: 0:06:32)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.468s + 0.004s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.513s + 0.004s (eta: 0:05:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.515s + 0.003s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.517s + 0.003s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.521s + 0.003s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.520s + 0.003s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.525s + 0.003s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.520s + 0.003s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.523s + 0.003s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.526s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.527s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.523s + 0.003s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.524s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.524s + 0.003s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.521s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.521s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.520s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.521s + 0.002s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.521s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.522s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.521s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.521s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.519s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.521s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.522s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.524s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.522s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.521s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.520s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.519s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.518s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.519s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.520s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.520s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.521s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.521s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.522s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.521s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.521s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.520s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.520s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.518s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.519s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.519s + 0.002s (eta: 0:01:32)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.519s + 0.002s (eta: 0:01:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.518s + 0.002s (eta: 0:01:22)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.518s + 0.002s (eta: 0:01:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.518s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.518s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.518s + 0.002s (eta: 0:01:01)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.517s + 0.002s (eta: 0:00:56)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.517s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.517s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.516s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.516s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.516s + 0.002s (eta: 0:00:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.516s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.516s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.516s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.516s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.515s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step17499.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.702s + 0.002s (eta: 0:07:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.518s + 0.002s (eta: 0:05:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.527s + 0.002s (eta: 0:05:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.526s + 0.002s (eta: 0:05:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.534s + 0.002s (eta: 0:05:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.536s + 0.002s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.538s + 0.002s (eta: 0:05:01)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.536s + 0.002s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.530s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.530s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.530s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.531s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.528s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.524s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.523s + 0.002s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.522s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.522s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.523s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.522s + 0.002s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.520s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.520s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.520s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.518s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.517s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.519s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.517s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.518s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.518s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.518s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.517s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.517s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.518s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.518s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.519s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.518s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.519s + 0.002s (eta: 0:02:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.518s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.516s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.515s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.515s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.515s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.516s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.518s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.517s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.516s + 0.002s (eta: 0:01:32)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.516s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.515s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.515s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.515s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.514s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.515s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.514s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.513s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.513s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.513s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.512s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.513s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.513s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.512s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.512s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.512s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.511s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 335.818s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [1825 1781 1080 ...  735  330 1588]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.8013
INFO voc_eval.py: 171: [1399  995  322 ... 1496  383 1071]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8161
INFO voc_eval.py: 171: [ 912 1489 1123 ...  305  297 1413]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.7292
INFO voc_eval.py: 171: [2225 3146  120 ... 1741  685 2612]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6470
INFO voc_eval.py: 171: [1533 2882  239 ...  770  268 3511]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.6533
INFO voc_eval.py: 171: [ 574  852 1485 ...   86 1482  698]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.8084
INFO voc_eval.py: 171: [3761 7556 4937 ... 2300 1762 2236]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8651
INFO voc_eval.py: 171: [  80  362  663 ...  149 1022  143]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8282
INFO voc_eval.py: 171: [ 224  225 5477 ... 1275 4397 2595]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6196
INFO voc_eval.py: 171: [1125  670  315 ...  685 1007 1076]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.7830
INFO voc_eval.py: 171: [ 918 1220  430 ... 1424 2397 1918]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.6894
INFO voc_eval.py: 171: [ 131 1285  527 ... 1094  674 1215]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8160
INFO voc_eval.py: 171: [  42  153  523 ...  849 1292 1308]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8193
INFO voc_eval.py: 171: [ 583 1867  319 ...  761  571  663]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.7984
INFO voc_eval.py: 171: [22941   399 18535 ... 11937  7537 20439]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8318
INFO voc_eval.py: 171: [4032 1574 3155 ... 2599 3917 2311]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.4704
INFO voc_eval.py: 171: [  74  530 1202 ...  517 1414  740]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.7548
INFO voc_eval.py: 171: [1111 1639  405 ...  486 1167 1769]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7320
INFO voc_eval.py: 171: [ 221 1052   42 ...  549  460  395]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.7963
INFO voc_eval.py: 171: [ 887 1318  572 ...  380 1373  822]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7332
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7496
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.801
INFO voc_dataset_evaluator.py: 134: 0.816
INFO voc_dataset_evaluator.py: 134: 0.729
INFO voc_dataset_evaluator.py: 134: 0.647
INFO voc_dataset_evaluator.py: 134: 0.653
INFO voc_dataset_evaluator.py: 134: 0.808
INFO voc_dataset_evaluator.py: 134: 0.865
INFO voc_dataset_evaluator.py: 134: 0.828
INFO voc_dataset_evaluator.py: 134: 0.620
INFO voc_dataset_evaluator.py: 134: 0.783
INFO voc_dataset_evaluator.py: 134: 0.689
INFO voc_dataset_evaluator.py: 134: 0.816
INFO voc_dataset_evaluator.py: 134: 0.819
INFO voc_dataset_evaluator.py: 134: 0.798
INFO voc_dataset_evaluator.py: 134: 0.832
INFO voc_dataset_evaluator.py: 134: 0.470
INFO voc_dataset_evaluator.py: 134: 0.755
INFO voc_dataset_evaluator.py: 134: 0.732
INFO voc_dataset_evaluator.py: 134: 0.796
INFO voc_dataset_evaluator.py: 134: 0.733
INFO voc_dataset_evaluator.py: 135: 0.750
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
Start testing on iteration 19999
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.554s + 0.001s (eta: 0:05:42)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.557s + 0.003s (eta: 0:05:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.527s + 0.004s (eta: 0:05:17)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.528s + 0.003s (eta: 0:05:12)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.518s + 0.003s (eta: 0:05:01)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.521s + 0.003s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.520s + 0.003s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.519s + 0.003s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.521s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.515s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.514s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.509s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.509s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.507s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.508s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.508s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.509s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.506s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.505s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.507s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.507s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.507s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.504s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.504s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.504s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.504s + 0.003s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.504s + 0.003s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.504s + 0.003s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.503s + 0.003s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.503s + 0.003s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.502s + 0.003s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.501s + 0.003s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.498s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.498s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.498s + 0.002s (eta: 0:02:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.498s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.499s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.498s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.498s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.498s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.496s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.495s + 0.003s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.495s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.496s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.496s + 0.002s (eta: 0:01:28)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.497s + 0.002s (eta: 0:01:23)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.496s + 0.002s (eta: 0:01:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.496s + 0.002s (eta: 0:01:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.495s + 0.002s (eta: 0:01:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.495s + 0.002s (eta: 0:01:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.495s + 0.002s (eta: 0:00:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.496s + 0.002s (eta: 0:00:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.496s + 0.002s (eta: 0:00:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.495s + 0.002s (eta: 0:00:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.495s + 0.002s (eta: 0:00:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.495s + 0.002s (eta: 0:00:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.496s + 0.002s (eta: 0:00:28)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.496s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.496s + 0.002s (eta: 0:00:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.495s + 0.002s (eta: 0:00:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.496s + 0.002s (eta: 0:00:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.495s + 0.002s (eta: 0:00:03)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.611s + 0.001s (eta: 0:06:18)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.492s + 0.002s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.506s + 0.003s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.520s + 0.002s (eta: 0:05:06)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.517s + 0.002s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.518s + 0.002s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.520s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.517s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.516s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.515s + 0.003s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.510s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.510s + 0.003s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.510s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.509s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.510s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.506s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.507s + 0.002s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.507s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.509s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.510s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.509s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.510s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.511s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.512s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.512s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.513s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.513s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.515s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.515s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.514s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.515s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.516s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.517s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.517s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.516s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.516s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.515s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.516s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.515s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.514s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.514s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.514s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.515s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.515s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.514s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.515s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.514s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.515s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.515s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.514s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.513s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.513s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.513s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.513s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.513s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.512s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.513s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.512s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.513s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.513s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.512s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.510s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.574s + 0.002s (eta: 0:05:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.515s + 0.001s (eta: 0:05:13)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.523s + 0.001s (eta: 0:05:13)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.521s + 0.001s (eta: 0:05:07)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.529s + 0.002s (eta: 0:05:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.521s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.522s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.521s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.517s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.512s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.516s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.517s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.512s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.515s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.519s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.518s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.519s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.519s + 0.002s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.520s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.523s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.522s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.521s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.518s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.519s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.520s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.520s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.521s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.520s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.519s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.519s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.519s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.519s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.519s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.519s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.521s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.520s + 0.002s (eta: 0:02:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.521s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.522s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.522s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.521s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.523s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.522s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.522s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.521s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.521s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.521s + 0.002s (eta: 0:01:27)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.521s + 0.002s (eta: 0:01:22)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.521s + 0.002s (eta: 0:01:17)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.519s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.519s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.519s + 0.002s (eta: 0:01:01)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.519s + 0.002s (eta: 0:00:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.519s + 0.002s (eta: 0:00:51)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.519s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.520s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.519s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.520s + 0.002s (eta: 0:00:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.519s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.519s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.519s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.517s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.515s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.11s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.580s + 0.001s (eta: 0:05:58)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.513s + 0.002s (eta: 0:05:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.496s + 0.003s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.486s + 0.003s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.485s + 0.003s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.485s + 0.003s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.490s + 0.003s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.495s + 0.003s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.495s + 0.003s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.497s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.498s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.497s + 0.003s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.498s + 0.003s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.503s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.503s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.503s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.504s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.506s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.504s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.504s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.501s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.503s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.502s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.503s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.504s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.506s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.506s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.505s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.505s + 0.003s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.506s + 0.003s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.505s + 0.003s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.504s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.505s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.506s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.506s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.506s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.508s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.508s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.508s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.508s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.509s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.510s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.511s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.511s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.512s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.511s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.512s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.512s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.512s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.512s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.512s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.512s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.511s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.512s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.512s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.512s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.512s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.512s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.512s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.512s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.512s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.511s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.700s + 0.002s (eta: 0:07:13)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.506s + 0.002s (eta: 0:05:08)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.506s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.517s + 0.002s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.521s + 0.002s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.521s + 0.002s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.520s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.515s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.507s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.514s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.516s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.519s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.521s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.519s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.519s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.519s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.518s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.518s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.517s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.517s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.518s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.518s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.518s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.515s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.515s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.514s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.514s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.513s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.514s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.514s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.514s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.513s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.513s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.511s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.512s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.511s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.512s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.513s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.513s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.512s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.512s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.512s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.512s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.511s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.512s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.510s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.510s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.510s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.510s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.509s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.509s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.509s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.510s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.509s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.508s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.508s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.507s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.508s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.507s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.720s + 0.006s (eta: 0:07:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.482s + 0.008s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.489s + 0.005s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.475s + 0.004s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.486s + 0.003s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.490s + 0.003s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.499s + 0.003s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.509s + 0.003s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.516s + 0.003s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.519s + 0.003s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.518s + 0.003s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.513s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.514s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.513s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.511s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.511s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.510s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.508s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.507s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.505s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.508s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.508s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.509s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.508s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.507s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.506s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.506s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.506s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.506s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.506s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.506s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.506s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.505s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.505s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.503s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.504s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.504s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.504s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.503s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.502s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.502s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.502s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.502s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.502s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.501s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.500s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.500s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.500s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.500s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.499s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.500s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.500s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.500s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.500s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.499s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.499s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.498s + 0.002s (eta: 0:00:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.498s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.498s + 0.002s (eta: 0:00:18)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.497s + 0.002s (eta: 0:00:13)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.497s + 0.002s (eta: 0:00:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.497s + 0.002s (eta: 0:00:03)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.558s + 0.001s (eta: 0:05:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.484s + 0.001s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.498s + 0.003s (eta: 0:04:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.491s + 0.002s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.487s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.498s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.492s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.497s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.495s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.500s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.501s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.503s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.504s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.504s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.506s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.506s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.508s + 0.002s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.506s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.506s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.505s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.507s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.505s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.504s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.506s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.507s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.508s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.506s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.506s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.507s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.509s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.508s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.508s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.509s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.509s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.510s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.509s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.509s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.510s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.511s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.511s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.510s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.509s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.509s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.509s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.510s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.510s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.510s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.510s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.510s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.508s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.509s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.510s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.509s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.510s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.509s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.509s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.510s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.511s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.511s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.510s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.510s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.509s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step19999.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.575s + 0.001s (eta: 0:05:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.500s + 0.001s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.488s + 0.001s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.501s + 0.001s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.504s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.505s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.509s + 0.002s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.505s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.506s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.506s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.506s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.505s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.505s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.506s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.503s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.505s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.503s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.505s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.506s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.504s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.503s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.502s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.503s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.501s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.500s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.500s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.500s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.498s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.498s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.500s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.498s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.497s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.497s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.497s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.497s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.497s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.495s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.494s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.494s + 0.002s (eta: 0:01:58)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.494s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.494s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.495s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.494s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.493s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.492s + 0.002s (eta: 0:01:27)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.491s + 0.002s (eta: 0:01:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.492s + 0.002s (eta: 0:01:18)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.491s + 0.002s (eta: 0:01:12)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.492s + 0.002s (eta: 0:01:08)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.491s + 0.002s (eta: 0:01:03)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.492s + 0.002s (eta: 0:00:58)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.492s + 0.002s (eta: 0:00:53)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.492s + 0.002s (eta: 0:00:48)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.493s + 0.002s (eta: 0:00:43)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.493s + 0.002s (eta: 0:00:38)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.493s + 0.002s (eta: 0:00:33)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.492s + 0.002s (eta: 0:00:28)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.492s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.493s + 0.002s (eta: 0:00:18)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.492s + 0.002s (eta: 0:00:13)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.493s + 0.002s (eta: 0:00:08)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.493s + 0.002s (eta: 0:00:03)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 337.549s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [1820 1067 1776 ...  891   26  562]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.8008
INFO voc_eval.py: 171: [ 320 1387  986 ...  731 1140 1432]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8185
INFO voc_eval.py: 171: [ 911 1493 1831 ... 1033  677 1144]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.7269
INFO voc_eval.py: 171: [2220 3144  122 ... 1289 1608 1862]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6473
INFO voc_eval.py: 171: [1534  238 2890 ...  469  455  521]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.6517
INFO voc_eval.py: 171: [ 573 1150 1485 ... 1359 1045  680]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.7996
INFO voc_eval.py: 171: [7582 6560 3773 ...  751 4779 2793]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8644
INFO voc_eval.py: 171: [  80  662  362 ... 1024  261 1109]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8267
INFO voc_eval.py: 171: [ 227  228 5474 ... 4748 9139 9924]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6202
INFO voc_eval.py: 171: [1132  672  314 ...  355  402  550]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.7805
INFO voc_eval.py: 171: [ 922 1223  434 ...  166  673 1202]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.6868
INFO voc_eval.py: 171: [ 130 1289  529 ... 1483  257  829]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8144
INFO voc_eval.py: 171: [  40  527  154 ... 1629  679  526]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8190
INFO voc_eval.py: 171: [ 585 1863  321 ... 1568 1440  853]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.7972
INFO voc_eval.py: 171: [22986  9034   392 ...  5732  3396 12602]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8306
INFO voc_eval.py: 171: [4010 1569  411 ... 2654 3869  331]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.4689
INFO voc_eval.py: 171: [  74  531  514 ... 1072 1661  512]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.7500
INFO voc_eval.py: 171: [1111 1644  409 ...  239 1773 1510]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7317
INFO voc_eval.py: 171: [ 218   82 1627 ...  275  857 1147]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.7969
INFO voc_eval.py: 171: [ 885 1310  228 ... 1538  734  433]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7323
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7482
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.801
INFO voc_dataset_evaluator.py: 134: 0.819
INFO voc_dataset_evaluator.py: 134: 0.727
INFO voc_dataset_evaluator.py: 134: 0.647
INFO voc_dataset_evaluator.py: 134: 0.652
INFO voc_dataset_evaluator.py: 134: 0.800
INFO voc_dataset_evaluator.py: 134: 0.864
INFO voc_dataset_evaluator.py: 134: 0.827
INFO voc_dataset_evaluator.py: 134: 0.620
INFO voc_dataset_evaluator.py: 134: 0.781
INFO voc_dataset_evaluator.py: 134: 0.687
INFO voc_dataset_evaluator.py: 134: 0.814
INFO voc_dataset_evaluator.py: 134: 0.819
INFO voc_dataset_evaluator.py: 134: 0.797
INFO voc_dataset_evaluator.py: 134: 0.831
INFO voc_dataset_evaluator.py: 134: 0.469
INFO voc_dataset_evaluator.py: 134: 0.750
INFO voc_dataset_evaluator.py: 134: 0.732
INFO voc_dataset_evaluator.py: 134: 0.797
INFO voc_dataset_evaluator.py: 134: 0.732
INFO voc_dataset_evaluator.py: 135: 0.748
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
Start testing on iteration 22499
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.777s + 0.002s (eta: 0:08:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.540s + 0.002s (eta: 0:05:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.510s + 0.002s (eta: 0:05:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.500s + 0.002s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.504s + 0.003s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.518s + 0.003s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.519s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.522s + 0.003s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.524s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.519s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.518s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.523s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.522s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.520s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.522s + 0.002s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.522s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.521s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.519s + 0.002s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.518s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.517s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.517s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.515s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.512s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.511s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.513s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.514s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.513s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.512s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.512s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.513s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.512s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.511s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.511s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.509s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.508s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.508s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.508s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.508s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.507s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.508s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.506s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.507s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.505s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.505s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.506s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.507s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.507s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.507s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.507s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.507s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.507s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.507s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.508s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.508s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.507s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.506s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.507s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.506s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.506s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.506s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.505s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.505s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.864s + 0.002s (eta: 0:08:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.509s + 0.001s (eta: 0:05:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.494s + 0.001s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.500s + 0.001s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.507s + 0.002s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.513s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.505s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.506s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.509s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.517s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.518s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.521s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.521s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.520s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.517s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.518s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.518s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.517s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.515s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.513s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.512s + 0.002s (eta: 0:03:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.512s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.510s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.511s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.510s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.509s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.510s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.510s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.509s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.509s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.510s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.509s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.508s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.507s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.506s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.506s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.507s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.506s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.506s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.507s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.506s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.504s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.504s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.504s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.504s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.505s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.505s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.506s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.506s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.506s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.506s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.505s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.505s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.506s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.505s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.505s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.506s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.507s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.507s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.507s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.506s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.506s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.679s + 0.002s (eta: 0:07:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.514s + 0.001s (eta: 0:05:13)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.508s + 0.002s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.516s + 0.002s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.514s + 0.002s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.517s + 0.002s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.511s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.508s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.506s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.512s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.509s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.505s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.506s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.504s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.503s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.502s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.501s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.499s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.503s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.502s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.502s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.502s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.501s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.501s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.502s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.500s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.501s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.501s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.501s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.500s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.499s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.497s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.497s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.497s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.498s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.499s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.500s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.500s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.501s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.500s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.500s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.500s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.499s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.499s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.499s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.499s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.499s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.499s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.500s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.499s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.499s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.499s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.498s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.499s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.498s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.499s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.499s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.499s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.499s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.499s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.498s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.498s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.565s + 0.001s (eta: 0:05:49)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.470s + 0.006s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.516s + 0.004s (eta: 0:05:10)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.508s + 0.003s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.513s + 0.003s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.505s + 0.003s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.503s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.512s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.517s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.520s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.520s + 0.003s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.522s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.522s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.527s + 0.003s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.527s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.523s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.521s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.521s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.520s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.521s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.521s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.521s + 0.003s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.521s + 0.003s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.521s + 0.003s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.521s + 0.003s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.522s + 0.003s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.521s + 0.003s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.519s + 0.003s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.518s + 0.003s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.519s + 0.003s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.518s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.517s + 0.003s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.517s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.516s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.514s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.513s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.514s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.513s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.512s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.513s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.512s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.511s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.512s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.512s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.511s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.512s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.511s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.511s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.510s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.510s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.510s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.509s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.509s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.508s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.509s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.509s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.509s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.509s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.508s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.507s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.907s + 0.001s (eta: 0:09:21)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.544s + 0.003s (eta: 0:05:32)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.562s + 0.003s (eta: 0:05:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.553s + 0.002s (eta: 0:05:26)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.538s + 0.002s (eta: 0:05:12)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.533s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.540s + 0.002s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.541s + 0.002s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.541s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.533s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.527s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.525s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.520s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.520s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.517s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.518s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.520s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.518s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.517s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.518s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.519s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.518s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.519s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.517s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.518s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.518s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.516s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.516s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.516s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.515s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.516s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.515s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.515s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.514s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.514s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.515s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.513s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.513s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.514s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.514s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.514s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.514s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.514s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.513s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.513s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.512s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.511s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.511s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.511s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.511s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.510s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.510s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.510s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.510s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.510s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.510s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.509s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.508s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.506s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.584s + 0.001s (eta: 0:06:01)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.497s + 0.001s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.491s + 0.002s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.485s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.479s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.487s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.488s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.492s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.493s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.493s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.493s + 0.003s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.493s + 0.003s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.492s + 0.003s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.490s + 0.003s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.490s + 0.003s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.490s + 0.003s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.488s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.490s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.491s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.492s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.492s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.492s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.493s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.494s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.495s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.496s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.498s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.497s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.498s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.498s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.499s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.499s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.499s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.499s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.499s + 0.002s (eta: 0:02:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.499s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.499s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.500s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.499s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.500s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.501s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.500s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.501s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.501s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.502s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.502s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.503s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.503s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.504s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.504s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.504s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.505s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.507s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.507s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.507s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.508s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.508s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.508s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.506s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.674s + 0.001s (eta: 0:06:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.514s + 0.001s (eta: 0:05:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.483s + 0.001s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.492s + 0.001s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.487s + 0.001s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.496s + 0.001s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.500s + 0.001s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.495s + 0.001s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.492s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.493s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.491s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.494s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.495s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.492s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.491s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.491s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.493s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.492s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.493s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.495s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.494s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.494s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.493s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.493s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.492s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.492s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.492s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.494s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.494s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.493s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.493s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.494s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.494s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.494s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.495s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.494s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.494s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.494s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.494s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.493s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.493s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.493s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.493s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.494s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.495s + 0.002s (eta: 0:01:28)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.495s + 0.002s (eta: 0:01:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.495s + 0.002s (eta: 0:01:18)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.495s + 0.002s (eta: 0:01:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.495s + 0.002s (eta: 0:01:08)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.495s + 0.002s (eta: 0:01:03)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.495s + 0.002s (eta: 0:00:58)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.495s + 0.002s (eta: 0:00:53)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.495s + 0.002s (eta: 0:00:48)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.495s + 0.002s (eta: 0:00:43)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.495s + 0.002s (eta: 0:00:38)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.495s + 0.002s (eta: 0:00:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.496s + 0.002s (eta: 0:00:28)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.496s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.497s + 0.002s (eta: 0:00:18)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.497s + 0.002s (eta: 0:00:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.497s + 0.002s (eta: 0:00:08)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.497s + 0.002s (eta: 0:00:03)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step22499.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.624s + 0.001s (eta: 0:06:26)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.501s + 0.005s (eta: 0:05:07)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.507s + 0.004s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.497s + 0.005s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.495s + 0.004s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.492s + 0.004s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.494s + 0.003s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.490s + 0.003s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.491s + 0.003s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.493s + 0.003s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.493s + 0.003s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.494s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.493s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.491s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.488s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.487s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.487s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.486s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.487s + 0.002s (eta: 0:03:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.488s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.489s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.491s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.493s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.493s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.491s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.491s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.489s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.488s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.489s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.488s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.488s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.487s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.488s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.488s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.489s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.489s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.489s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.488s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.489s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.489s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.489s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.489s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.489s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.489s + 0.002s (eta: 0:01:32)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.489s + 0.002s (eta: 0:01:27)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.488s + 0.002s (eta: 0:01:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.488s + 0.002s (eta: 0:01:17)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.488s + 0.002s (eta: 0:01:12)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.489s + 0.002s (eta: 0:01:07)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.489s + 0.002s (eta: 0:01:02)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.489s + 0.002s (eta: 0:00:57)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.489s + 0.002s (eta: 0:00:53)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.490s + 0.002s (eta: 0:00:48)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.490s + 0.002s (eta: 0:00:43)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.491s + 0.002s (eta: 0:00:38)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.492s + 0.002s (eta: 0:00:33)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.491s + 0.002s (eta: 0:00:28)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.491s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.491s + 0.002s (eta: 0:00:18)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.491s + 0.002s (eta: 0:00:13)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.492s + 0.002s (eta: 0:00:08)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.493s + 0.002s (eta: 0:00:03)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 334.287s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [1810 1766 1054 ...  693 1724 1794]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.7989
INFO voc_eval.py: 171: [1385  988  319 ...  521 2054 1689]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8229
INFO voc_eval.py: 171: [ 906 1486 1828 ... 1810 1149 1219]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.7247
INFO voc_eval.py: 171: [2229 3149  123 ...  146  870 3184]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6456
INFO voc_eval.py: 171: [1524 2872  234 ... 2414  411  324]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.6488
INFO voc_eval.py: 171: [ 572 1490  145 ... 1191  768 1124]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.7980
INFO voc_eval.py: 171: [7571 6547 4900 ... 1337 3273  928]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8641
INFO voc_eval.py: 171: [  81  666  996 ...  144  281 1058]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8273
INFO voc_eval.py: 171: [ 224  225 1250 ... 2309 7996 9946]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6179
INFO voc_eval.py: 171: [1133  673  312 ...  688  384 1395]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.7777
INFO voc_eval.py: 171: [ 915 1217 2524 ...  873 2300 2784]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.6711
INFO voc_eval.py: 171: [ 130 1286  530 ... 1099  123  695]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8108
INFO voc_eval.py: 171: [  43  161  536 ...   49 1383   82]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8193
INFO voc_eval.py: 171: [ 580 1853  318 ...  495  342  768]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.7956
INFO voc_eval.py: 171: [23080  6948 18651 ... 10942 19140  5738]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8302
INFO voc_eval.py: 171: [3999 1557  406 ...  660 2571 3985]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.4667
INFO voc_eval.py: 171: [  71  527 1211 ...  245 1443  968]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.7574
INFO voc_eval.py: 171: [1125 1662  417 ...  508  586 2254]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7305
INFO voc_eval.py: 171: [ 220   43 1658 ...  245  668  112]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.7956
INFO voc_eval.py: 171: [ 894  231 1317 ... 1147 1270  742]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7310
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7467
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.799
INFO voc_dataset_evaluator.py: 134: 0.823
INFO voc_dataset_evaluator.py: 134: 0.725
INFO voc_dataset_evaluator.py: 134: 0.646
INFO voc_dataset_evaluator.py: 134: 0.649
INFO voc_dataset_evaluator.py: 134: 0.798
INFO voc_dataset_evaluator.py: 134: 0.864
INFO voc_dataset_evaluator.py: 134: 0.827
INFO voc_dataset_evaluator.py: 134: 0.618
INFO voc_dataset_evaluator.py: 134: 0.778
INFO voc_dataset_evaluator.py: 134: 0.671
INFO voc_dataset_evaluator.py: 134: 0.811
INFO voc_dataset_evaluator.py: 134: 0.819
INFO voc_dataset_evaluator.py: 134: 0.796
INFO voc_dataset_evaluator.py: 134: 0.830
INFO voc_dataset_evaluator.py: 134: 0.467
INFO voc_dataset_evaluator.py: 134: 0.757
INFO voc_dataset_evaluator.py: 134: 0.731
INFO voc_dataset_evaluator.py: 134: 0.796
INFO voc_dataset_evaluator.py: 134: 0.731
INFO voc_dataset_evaluator.py: 135: 0.747
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
Start testing on iteration 24999
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.619s + 0.001s (eta: 0:06:22)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.501s + 0.001s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.512s + 0.001s (eta: 0:05:07)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.515s + 0.001s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.511s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.523s + 0.002s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.517s + 0.002s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.516s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.511s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.507s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.508s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.508s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.507s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.504s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.505s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.503s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.502s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.498s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.498s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.495s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.494s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.494s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.495s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.496s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.496s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.496s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.497s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.498s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.497s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.496s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.497s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.497s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.497s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.498s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.496s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.497s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.498s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.499s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.499s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.500s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.500s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.500s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.500s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.501s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.500s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.500s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.499s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.499s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.499s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.499s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.499s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.499s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.498s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.499s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.499s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.499s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.498s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.499s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.498s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.498s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.498s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.498s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.644s + 0.001s (eta: 0:06:38)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.548s + 0.002s (eta: 0:05:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.527s + 0.003s (eta: 0:05:16)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.528s + 0.003s (eta: 0:05:11)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.521s + 0.003s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.526s + 0.002s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.524s + 0.003s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.523s + 0.003s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.520s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.514s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.512s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.517s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.523s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.525s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.523s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.526s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.524s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.523s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.520s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.519s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.520s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.521s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.522s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.521s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.522s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.521s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.521s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.523s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.523s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.521s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.520s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.520s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.521s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.521s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.521s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.521s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.521s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.522s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.520s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.520s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.520s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.519s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.519s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.518s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.518s + 0.002s (eta: 0:01:32)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.518s + 0.002s (eta: 0:01:27)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.518s + 0.002s (eta: 0:01:22)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.517s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.518s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.518s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.518s + 0.002s (eta: 0:01:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.518s + 0.002s (eta: 0:00:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.518s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.518s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.517s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.516s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.516s + 0.002s (eta: 0:00:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.516s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.517s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.517s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.516s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.514s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.639s + 0.002s (eta: 0:06:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.513s + 0.002s (eta: 0:05:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.560s + 0.002s (eta: 0:05:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.551s + 0.002s (eta: 0:05:25)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.529s + 0.002s (eta: 0:05:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.521s + 0.002s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.516s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.515s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.520s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.520s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.517s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.519s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.521s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.519s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.521s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.520s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.518s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.516s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.513s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.511s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.510s + 0.002s (eta: 0:03:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.510s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.509s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.511s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.512s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.512s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.512s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.511s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.510s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.510s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.511s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.511s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.510s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.510s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.509s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.509s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.508s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.508s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.508s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.508s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.508s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.508s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.508s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.508s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.508s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.508s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.508s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.508s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.508s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.509s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.509s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.509s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.508s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.509s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.509s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.508s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.507s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.507s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.507s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.506s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.506s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.505s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.573s + 0.001s (eta: 0:05:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.529s + 0.001s (eta: 0:05:22)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.511s + 0.002s (eta: 0:05:06)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.523s + 0.002s (eta: 0:05:08)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.508s + 0.003s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.510s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.507s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.515s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.510s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.511s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.508s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.505s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.509s + 0.003s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.511s + 0.003s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.511s + 0.003s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.512s + 0.003s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.513s + 0.003s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.514s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.515s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.516s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.515s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.516s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.513s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.513s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.512s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.512s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.513s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.512s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.513s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.511s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.511s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.509s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.508s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.508s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.509s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.508s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.509s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.508s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.506s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.505s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.506s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.507s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.507s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.508s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.507s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.508s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.508s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.507s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.507s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.506s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.506s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.505s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.505s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.505s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.504s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.504s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.504s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.505s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.505s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.504s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.504s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.504s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.829s + 0.013s (eta: 0:08:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.520s + 0.003s (eta: 0:05:18)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.536s + 0.003s (eta: 0:05:22)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.522s + 0.002s (eta: 0:05:08)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.520s + 0.002s (eta: 0:05:01)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.514s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.520s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.524s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.524s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.523s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.522s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.519s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.514s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.513s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.514s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.518s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.518s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.515s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.517s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.518s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.516s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.514s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.512s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.512s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.512s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.512s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.512s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.512s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.512s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.511s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.510s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.509s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.509s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.508s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.508s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.509s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.508s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.508s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.508s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.508s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.508s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.507s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.507s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.506s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.507s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.506s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.506s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.507s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.506s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.507s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.506s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.506s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.506s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.506s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.506s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.506s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.506s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.506s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.506s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.506s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.506s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.507s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.724s + 0.002s (eta: 0:07:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.560s + 0.001s (eta: 0:05:41)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.536s + 0.002s (eta: 0:05:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.526s + 0.002s (eta: 0:05:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.523s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.524s + 0.002s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.532s + 0.002s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.528s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.522s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.521s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.520s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.520s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.521s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.522s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.523s + 0.002s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.524s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.524s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.522s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.522s + 0.002s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.520s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.521s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.521s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.521s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.520s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.517s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.516s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.515s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.515s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.515s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.514s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.513s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.512s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.512s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.512s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.512s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.512s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.512s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.513s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.512s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.512s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.511s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.512s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.513s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.513s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.513s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.513s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.512s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.511s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.510s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.509s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.509s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.509s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.509s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.508s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.507s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.508s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.508s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.507s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.507s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.507s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.627s + 0.001s (eta: 0:06:28)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.490s + 0.004s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.465s + 0.003s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.470s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.472s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.489s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.488s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.494s + 0.003s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.493s + 0.003s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.496s + 0.003s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.499s + 0.003s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.502s + 0.003s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.503s + 0.003s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.500s + 0.003s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.500s + 0.003s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.502s + 0.003s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.504s + 0.003s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.506s + 0.003s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.506s + 0.003s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.507s + 0.003s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.508s + 0.003s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.508s + 0.003s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.508s + 0.003s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.508s + 0.003s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.508s + 0.003s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.508s + 0.003s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.508s + 0.003s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.508s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.508s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.509s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.509s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.508s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.507s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.506s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.508s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.507s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.506s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.505s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.506s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.505s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.505s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.505s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.505s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.504s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.504s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.504s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.503s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.504s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.505s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.505s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.505s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.505s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.506s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.505s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.505s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.506s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.505s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.504s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.505s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.506s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.505s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.505s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step24999.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.611s + 0.001s (eta: 0:06:18)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.518s + 0.002s (eta: 0:05:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.520s + 0.002s (eta: 0:05:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.512s + 0.002s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.498s + 0.002s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.499s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.495s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.495s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.500s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.506s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.503s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.508s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.508s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.506s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.506s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.506s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.506s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.505s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.504s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.504s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.504s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.505s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.507s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.506s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.507s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.506s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.507s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.505s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.503s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.503s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.502s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.502s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.504s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.502s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.503s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.502s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.501s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.501s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.501s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.501s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.502s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.501s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.502s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.501s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.501s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.501s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.502s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.501s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.502s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.503s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.503s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.503s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.502s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.502s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.503s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.503s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.503s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.502s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.503s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.504s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.503s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.503s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 336.432s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [1812 1771 1058 ... 1900  552 1782]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.7950
INFO voc_eval.py: 171: [ 321 1391  995 ... 1847 1894 1639]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8217
INFO voc_eval.py: 171: [ 903 1833 1483 ... 1013 1689 1653]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.7234
INFO voc_eval.py: 171: [2248 3165  129 ... 2749 2739   93]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6502
INFO voc_eval.py: 171: [1513  227 2850 ... 2646 2068  887]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.6467
INFO voc_eval.py: 171: [ 569  143 1484 ...  722  329 1206]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.7967
INFO voc_eval.py: 171: [4925 6567 7600 ...  625 3011  205]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8621
INFO voc_eval.py: 171: [ 669  366  998 ...  912  617 1395]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8254
INFO voc_eval.py: 171: [ 221  222 5459 ... 8246  206 6570]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6156
INFO voc_eval.py: 171: [1138  677 1137 ...  376  399 1480]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.7770
INFO voc_eval.py: 171: [ 903 1202 2503 ... 1496 2180  758]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.6698
INFO voc_eval.py: 171: [1288  129 1264 ... 1866 1000 1149]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8081
INFO voc_eval.py: 171: [ 43 164 540 ...  87 775 266]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8192
INFO voc_eval.py: 171: [ 582 1857  320 ...  667  577  116]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.7886
INFO voc_eval.py: 171: [23140  9069  6971 ... 20761 16567 18267]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8286
INFO voc_eval.py: 171: [3967 1534  395 ... 2697  484 1048]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.4635
INFO voc_eval.py: 171: [  70  523 1207 ... 1431 1517  206]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.7598
INFO voc_eval.py: 171: [1120 1657  416 ...  643  328   31]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7286
INFO voc_eval.py: 171: [ 220 1651   41 ... 1492  761 1358]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.7938
INFO voc_eval.py: 171: [ 894  234 1309 ... 1428  948  761]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7335
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7454
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.795
INFO voc_dataset_evaluator.py: 134: 0.822
INFO voc_dataset_evaluator.py: 134: 0.723
INFO voc_dataset_evaluator.py: 134: 0.650
INFO voc_dataset_evaluator.py: 134: 0.647
INFO voc_dataset_evaluator.py: 134: 0.797
INFO voc_dataset_evaluator.py: 134: 0.862
INFO voc_dataset_evaluator.py: 134: 0.825
INFO voc_dataset_evaluator.py: 134: 0.616
INFO voc_dataset_evaluator.py: 134: 0.777
INFO voc_dataset_evaluator.py: 134: 0.670
INFO voc_dataset_evaluator.py: 134: 0.808
INFO voc_dataset_evaluator.py: 134: 0.819
INFO voc_dataset_evaluator.py: 134: 0.789
INFO voc_dataset_evaluator.py: 134: 0.829
INFO voc_dataset_evaluator.py: 134: 0.463
INFO voc_dataset_evaluator.py: 134: 0.760
INFO voc_dataset_evaluator.py: 134: 0.729
INFO voc_dataset_evaluator.py: 134: 0.794
INFO voc_dataset_evaluator.py: 134: 0.733
INFO voc_dataset_evaluator.py: 135: 0.745
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
Start testing on iteration 27499
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.710s + 0.001s (eta: 0:07:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.510s + 0.004s (eta: 0:05:12)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.481s + 0.003s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.475s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.484s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.489s + 0.003s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.499s + 0.003s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.505s + 0.003s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.503s + 0.003s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.502s + 0.003s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.502s + 0.003s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.506s + 0.003s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.507s + 0.003s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.509s + 0.003s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.514s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.516s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.516s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.518s + 0.002s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.520s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.520s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.522s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.521s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.519s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.519s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.518s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.517s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.515s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.516s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.516s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.516s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.515s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.515s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.515s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.516s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.516s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.516s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.517s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.515s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.518s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.517s + 0.002s (eta: 0:01:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.517s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.517s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.517s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.517s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.516s + 0.002s (eta: 0:01:32)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.516s + 0.002s (eta: 0:01:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.516s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.516s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.515s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.516s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.516s + 0.002s (eta: 0:01:01)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.516s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.517s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.516s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.516s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.516s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.516s + 0.002s (eta: 0:00:30)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.516s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.515s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.515s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.514s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.514s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.718s + 0.001s (eta: 0:07:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.495s + 0.003s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.494s + 0.003s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.506s + 0.002s (eta: 0:04:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.525s + 0.002s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.531s + 0.002s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.523s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.515s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.511s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.509s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.509s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.508s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.507s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.508s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.506s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.507s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.504s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.502s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.502s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.503s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.503s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.503s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.504s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.506s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.507s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.507s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.507s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.507s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.508s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.508s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.508s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.508s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.508s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.508s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.508s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.507s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.508s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.509s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.509s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.510s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.510s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.510s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.510s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.509s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.508s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.509s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.509s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.509s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.510s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.509s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.509s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.508s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.509s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.509s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.509s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.510s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.510s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.509s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.509s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.507s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.507s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.11s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.677s + 0.001s (eta: 0:06:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.519s + 0.004s (eta: 0:05:17)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.507s + 0.003s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.517s + 0.002s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.516s + 0.002s (eta: 0:04:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.520s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.519s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.527s + 0.002s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.523s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.520s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.523s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.522s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.521s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.522s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.521s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.521s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.521s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.521s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.520s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.519s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.518s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.518s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.520s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.520s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.519s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.519s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.519s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.518s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.517s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.517s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.518s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.518s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.519s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.518s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.517s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.518s + 0.002s (eta: 0:02:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.517s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.518s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.518s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.517s + 0.002s (eta: 0:01:58)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.517s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.517s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.515s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.515s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.515s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.514s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.514s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.513s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.513s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.513s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.514s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.514s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.514s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.515s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.513s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.513s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.512s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.512s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.511s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.511s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.511s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.511s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.11s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.506s + 0.001s (eta: 0:05:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.478s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.475s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.500s + 0.002s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.498s + 0.003s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.509s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.511s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.516s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.510s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.506s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.505s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.501s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.500s + 0.002s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.502s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.503s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.500s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.502s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.504s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.506s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.509s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.511s + 0.002s (eta: 0:03:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.512s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.513s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.514s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.514s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.514s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.513s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.511s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.509s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.508s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.508s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.508s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.509s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.510s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.509s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.508s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.509s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.510s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.509s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.509s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.509s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.510s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.510s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.510s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.510s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.509s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.508s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.508s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.508s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.507s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.507s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.508s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.508s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.508s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.508s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.509s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.509s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.509s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.508s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.508s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.749s + 0.002s (eta: 0:07:43)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.554s + 0.001s (eta: 0:05:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.576s + 0.001s (eta: 0:05:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.552s + 0.002s (eta: 0:05:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.539s + 0.002s (eta: 0:05:12)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.525s + 0.002s (eta: 0:04:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.519s + 0.001s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.511s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.509s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.515s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.515s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.516s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.517s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.517s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.515s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.514s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.512s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.513s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.512s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.513s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.514s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.514s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.515s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.516s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.515s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.516s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.516s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.517s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.517s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.516s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.517s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.517s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.516s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.516s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.517s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.517s + 0.002s (eta: 0:02:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.518s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.517s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.517s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.517s + 0.002s (eta: 0:01:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.517s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.516s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.515s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.516s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.516s + 0.002s (eta: 0:01:32)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.516s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.516s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.517s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.516s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.516s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.516s + 0.002s (eta: 0:01:01)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.516s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.516s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.516s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.516s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.515s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.515s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.515s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.514s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.514s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.514s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.514s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.720s + 0.001s (eta: 0:07:25)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.537s + 0.001s (eta: 0:05:27)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.532s + 0.001s (eta: 0:05:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.533s + 0.001s (eta: 0:05:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.524s + 0.001s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.527s + 0.001s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.525s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.525s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.522s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.523s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.524s + 0.003s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.523s + 0.003s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.525s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.524s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.523s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.526s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.526s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.525s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.526s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.525s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.524s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.522s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.521s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.519s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.519s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.518s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.520s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.520s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.519s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.518s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.517s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.516s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.516s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.516s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.517s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.516s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.516s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.516s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.517s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.516s + 0.002s (eta: 0:01:58)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.515s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.516s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.515s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.514s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.514s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.513s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.514s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.514s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.514s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.513s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.515s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.515s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.516s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.515s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.515s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.515s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.515s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.515s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.514s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.513s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.514s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.512s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.735s + 0.001s (eta: 0:07:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.523s + 0.001s (eta: 0:05:18)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.510s + 0.002s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.510s + 0.002s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.505s + 0.003s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.506s + 0.003s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.507s + 0.003s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.509s + 0.003s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.505s + 0.003s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.505s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.506s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.505s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.506s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.507s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.506s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.506s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.504s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.502s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.503s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.500s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.498s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.498s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.500s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.499s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.499s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.502s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.503s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.503s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.503s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.503s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.505s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.507s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.507s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.506s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.506s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.505s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.505s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.505s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.504s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.504s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.504s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.504s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.504s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.505s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.505s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.505s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.504s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.503s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.503s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.504s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.505s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.506s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.506s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.507s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.507s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.508s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.508s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.508s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.509s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.508s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.11s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step27499.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.814s + 0.002s (eta: 0:08:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.547s + 0.001s (eta: 0:05:33)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.531s + 0.002s (eta: 0:05:18)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.515s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.509s + 0.002s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.504s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.507s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.508s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.512s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.511s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.511s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.510s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.513s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.515s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.511s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.514s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.512s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.514s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.515s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.517s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.518s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.519s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.520s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.521s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.518s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.516s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.517s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.517s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.517s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.518s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.518s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.516s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.516s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.515s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.516s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.516s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.514s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.514s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.514s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.515s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.514s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.514s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.514s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.514s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.514s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.514s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.514s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.514s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.513s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.513s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.512s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.511s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.511s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.511s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.510s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.510s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.510s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.510s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.511s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.511s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.512s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.512s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 337.520s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [1816 1773 1059 ... 1976 1122 1905]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.7917
INFO voc_eval.py: 171: [ 321  994 1390 ...  524  663 2016]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8214
INFO voc_eval.py: 171: [ 903 1490 1836 ... 1107 1117  282]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.7240
INFO voc_eval.py: 171: [2248 3168  128 ... 1583  284 1272]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6492
INFO voc_eval.py: 171: [1511  224 2845 ...  886  600  683]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.6471
INFO voc_eval.py: 171: [ 570 1484 1229 ...  488 1314  970]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.7939
INFO voc_eval.py: 171: [5020 4953 7637 ... 3352  274 5147]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8605
INFO voc_eval.py: 171: [  79  366  665 ... 1205 1299  142]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8238
INFO voc_eval.py: 171: [ 217  218 5475 ... 8540  273 3890]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6155
INFO voc_eval.py: 171: [1150  683 1149 ...  410  201  301]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.7772
INFO voc_eval.py: 171: [ 898 1196 2498 ... 2112  349   96]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.6819
INFO voc_eval.py: 171: [ 131 1292  527 ...   87 1455  940]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8089
INFO voc_eval.py: 171: [  44  547  167 ...  783 1234  220]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8186
INFO voc_eval.py: 171: [ 579  323 1865 ... 1625  662 1761]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.7839
INFO voc_eval.py: 171: [11013  6999  9108 ... 14296  4841 12378]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8283
INFO voc_eval.py: 171: [3945  398 1534 ...  213 3807 1101]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.4608
INFO voc_eval.py: 171: [  69  526 1215 ...  920   72  849]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.7605
INFO voc_eval.py: 171: [1133 1677  414 ...  941   57 1342]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7258
INFO voc_eval.py: 171: [ 219 1650   41 ...  489 1495 1043]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.7927
INFO voc_eval.py: 171: [ 897  236 1316 ...  742  558 1087]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7324
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7449
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.792
INFO voc_dataset_evaluator.py: 134: 0.821
INFO voc_dataset_evaluator.py: 134: 0.724
INFO voc_dataset_evaluator.py: 134: 0.649
INFO voc_dataset_evaluator.py: 134: 0.647
INFO voc_dataset_evaluator.py: 134: 0.794
INFO voc_dataset_evaluator.py: 134: 0.860
INFO voc_dataset_evaluator.py: 134: 0.824
INFO voc_dataset_evaluator.py: 134: 0.616
INFO voc_dataset_evaluator.py: 134: 0.777
INFO voc_dataset_evaluator.py: 134: 0.682
INFO voc_dataset_evaluator.py: 134: 0.809
INFO voc_dataset_evaluator.py: 134: 0.819
INFO voc_dataset_evaluator.py: 134: 0.784
INFO voc_dataset_evaluator.py: 134: 0.828
INFO voc_dataset_evaluator.py: 134: 0.461
INFO voc_dataset_evaluator.py: 134: 0.760
INFO voc_dataset_evaluator.py: 134: 0.726
INFO voc_dataset_evaluator.py: 134: 0.793
INFO voc_dataset_evaluator.py: 134: 0.732
INFO voc_dataset_evaluator.py: 135: 0.745
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
Start testing on iteration 29999
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.11s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.625s + 0.002s (eta: 0:06:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.488s + 0.001s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.500s + 0.002s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.497s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.498s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.502s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.508s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.507s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.506s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.509s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.507s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.506s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.506s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.504s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.505s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.506s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.509s + 0.002s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.509s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.507s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.508s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.508s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.510s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.510s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.509s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.509s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.510s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.509s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.509s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.509s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.508s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.508s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.508s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.508s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.508s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.508s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.508s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.508s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.507s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.508s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.507s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.506s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.505s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.504s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.504s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.504s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.503s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.503s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.503s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.504s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.504s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.504s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.504s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.505s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.504s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.503s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.503s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.503s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.503s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.503s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.503s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.504s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.503s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.667s + 0.051s (eta: 0:07:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.497s + 0.006s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.503s + 0.004s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.504s + 0.003s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.500s + 0.003s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.505s + 0.003s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.513s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.511s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.516s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.521s + 0.003s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.521s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.518s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.514s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.516s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.511s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.513s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.513s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.510s + 0.002s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.511s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.513s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.513s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.514s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.513s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.515s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.515s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.515s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.514s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.513s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.512s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.511s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.512s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.511s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.511s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.511s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.510s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.510s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.510s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.511s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.511s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.510s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.510s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.510s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.510s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.509s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.508s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.508s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.508s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.509s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.509s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.508s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.508s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.508s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.507s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.508s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.508s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.507s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.508s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.507s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.507s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.507s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.506s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.506s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.650s + 0.002s (eta: 0:06:42)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.542s + 0.002s (eta: 0:05:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.543s + 0.002s (eta: 0:05:25)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.526s + 0.002s (eta: 0:05:10)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.514s + 0.002s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.506s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.506s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.508s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.512s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.511s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.511s + 0.003s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.508s + 0.003s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.506s + 0.003s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.508s + 0.003s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.512s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.512s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.510s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.509s + 0.002s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.509s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.510s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.509s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.509s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.509s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.509s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.508s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.507s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.509s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.509s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.509s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.508s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.508s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.508s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.508s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.507s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.507s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.508s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.508s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.508s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.508s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.508s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.508s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.509s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.509s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.508s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.508s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.508s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.509s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.508s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.507s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.507s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.508s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.508s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.507s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.507s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.507s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.508s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.509s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.509s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.509s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.508s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.620s + 0.001s (eta: 0:06:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.488s + 0.003s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.497s + 0.002s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.498s + 0.002s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.496s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.505s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.497s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.496s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.501s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.504s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.505s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.508s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.508s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.509s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.506s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.511s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.512s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.513s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.513s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.515s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.514s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.514s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.511s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.512s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.513s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.513s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.511s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.509s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.510s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.509s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.509s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.508s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.507s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.507s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.508s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.507s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.508s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.508s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.508s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.507s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.508s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.508s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.508s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.507s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.506s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.507s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.507s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.507s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.506s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.507s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.506s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.505s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.505s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.505s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.506s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.505s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.506s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.507s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.507s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.507s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.506s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.506s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.724s + 0.001s (eta: 0:07:27)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.585s + 0.003s (eta: 0:05:57)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.541s + 0.002s (eta: 0:05:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.534s + 0.003s (eta: 0:05:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.533s + 0.003s (eta: 0:05:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.516s + 0.003s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.517s + 0.002s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.519s + 0.002s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.517s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.517s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.516s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.520s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.518s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.515s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.515s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.514s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.514s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.514s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.512s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.510s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.509s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.512s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.511s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.513s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.513s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.514s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.514s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.512s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.511s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.509s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.509s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.510s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.510s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.512s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.511s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.510s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.510s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.509s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.509s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.508s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.509s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.510s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.509s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.510s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.510s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.510s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.509s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.509s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.509s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.510s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.510s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.509s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.508s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.508s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.508s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.509s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.508s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.509s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.509s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.509s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.508s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.677s + 0.002s (eta: 0:06:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.530s + 0.001s (eta: 0:05:22)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.509s + 0.002s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.511s + 0.002s (eta: 0:05:01)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.517s + 0.002s (eta: 0:04:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.517s + 0.002s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.521s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.513s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.517s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.517s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.516s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.514s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.513s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.512s + 0.002s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.512s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.514s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.514s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.515s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.517s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.516s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.514s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.514s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.514s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.512s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.512s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.510s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.510s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.510s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.510s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.510s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.509s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.510s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.509s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.508s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.508s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.507s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.507s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.506s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.505s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.506s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.506s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.505s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.504s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.505s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.505s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.505s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.505s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.506s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.506s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.506s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.506s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.506s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.507s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.507s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.506s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.506s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.505s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.505s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.505s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.505s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.505s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.505s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.600s + 0.001s (eta: 0:06:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.480s + 0.001s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.484s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.497s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.504s + 0.003s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.511s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.513s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.526s + 0.002s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.520s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.523s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.523s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.522s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.522s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.523s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.520s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.520s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.519s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.517s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.519s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.519s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.519s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.519s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.519s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.517s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.515s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.516s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.515s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.515s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.514s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.514s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.513s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.514s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.515s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.517s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.517s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.517s + 0.002s (eta: 0:02:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.517s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.515s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.514s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.513s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.513s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.512s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.512s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.512s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.512s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.512s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.511s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.510s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.510s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.509s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.508s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.509s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.508s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.507s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.507s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.506s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.506s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.505s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.506s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.505s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.505s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.506s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step29999.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.614s + 0.004s (eta: 0:06:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.588s + 0.003s (eta: 0:05:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.561s + 0.002s (eta: 0:05:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.544s + 0.002s (eta: 0:05:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.534s + 0.002s (eta: 0:05:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.536s + 0.002s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.532s + 0.002s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.522s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.519s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.521s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.520s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.515s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.512s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.513s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.509s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.509s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.512s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.512s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.511s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.509s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.508s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.507s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.507s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.505s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.505s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.503s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.503s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.505s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.506s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.507s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.507s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.507s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.507s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.505s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.504s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.505s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.508s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.508s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.508s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.509s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.510s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.509s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.508s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.507s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.506s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.506s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.506s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.506s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.505s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.506s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.507s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.507s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.506s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.506s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.505s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.505s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.506s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.506s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.505s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.505s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.505s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.505s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 332.965s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [1820 1776 1059 ...  901  878   68]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.7912
INFO voc_eval.py: 171: [ 998 1396  323 ...  311 1737   40]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8204
INFO voc_eval.py: 171: [ 908 1492 1839 ... 1135 1461 1077]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.7238
INFO voc_eval.py: 171: [2248 3166  128 ... 1950  113 1138]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6491
INFO voc_eval.py: 171: [1512 2844  222 ... 1549  759 1679]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.6464
INFO voc_eval.py: 171: [ 569  144 1484 ... 1206  676 1494]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.7936
INFO voc_eval.py: 171: [4964 6620 5031 ...  507 5301 5079]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8603
INFO voc_eval.py: 171: [ 665   79  366 ...  897 1204 1326]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8242
INFO voc_eval.py: 171: [ 218  219 5480 ... 9564 6472 8562]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6151
INFO voc_eval.py: 171: [1153  686 1152 ...  910  251  622]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.7769
INFO voc_eval.py: 171: [ 897 1199 2497 ...  237 2251   96]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.6804
INFO voc_eval.py: 171: [ 132 1298  530 ... 1462   66 1189]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8093
INFO voc_eval.py: 171: [  45  167  551 ... 1205  896  220]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8210
INFO voc_eval.py: 171: [ 580 1865  323 ... 1872  575 1319]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.7836
INFO voc_eval.py: 171: [ 9116 11023  7007 ... 14231 16146 12080]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8288
INFO voc_eval.py: 171: [3941  398 1532 ... 2831 1053 2246]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.4601
INFO voc_eval.py: 171: [  70  526 1216 ...  179  688 1088]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.7602
INFO voc_eval.py: 171: [1132 1675  415 ...  646 1614 1579]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7275
INFO voc_eval.py: 171: [ 219 1651   41 ... 1065 1345  820]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.7925
INFO voc_eval.py: 171: [897 525 192 ... 557 787 285]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7325
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7448
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.791
INFO voc_dataset_evaluator.py: 134: 0.820
INFO voc_dataset_evaluator.py: 134: 0.724
INFO voc_dataset_evaluator.py: 134: 0.649
INFO voc_dataset_evaluator.py: 134: 0.646
INFO voc_dataset_evaluator.py: 134: 0.794
INFO voc_dataset_evaluator.py: 134: 0.860
INFO voc_dataset_evaluator.py: 134: 0.824
INFO voc_dataset_evaluator.py: 134: 0.615
INFO voc_dataset_evaluator.py: 134: 0.777
INFO voc_dataset_evaluator.py: 134: 0.680
INFO voc_dataset_evaluator.py: 134: 0.809
INFO voc_dataset_evaluator.py: 134: 0.821
INFO voc_dataset_evaluator.py: 134: 0.784
INFO voc_dataset_evaluator.py: 134: 0.829
INFO voc_dataset_evaluator.py: 134: 0.460
INFO voc_dataset_evaluator.py: 134: 0.760
INFO voc_dataset_evaluator.py: 134: 0.727
INFO voc_dataset_evaluator.py: 134: 0.792
INFO voc_dataset_evaluator.py: 134: 0.733
INFO voc_dataset_evaluator.py: 135: 0.745
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
Start testing on iteration 32499
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.11s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.528s + 0.001s (eta: 0:05:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.515s + 0.001s (eta: 0:05:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.528s + 0.002s (eta: 0:05:17)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.526s + 0.002s (eta: 0:05:10)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.533s + 0.002s (eta: 0:05:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.530s + 0.002s (eta: 0:05:01)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.528s + 0.002s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.528s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.522s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.516s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.516s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.513s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.512s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.513s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.510s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.510s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.509s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.509s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.508s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.508s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.509s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.510s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.509s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.509s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.508s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.508s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.509s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.510s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.510s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.511s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.511s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.511s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.511s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.511s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.510s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.509s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.509s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.509s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.509s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.509s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.509s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.509s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.510s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.510s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.510s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.510s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.511s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.511s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.511s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.511s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.511s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.511s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.511s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.510s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.510s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.510s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.510s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.510s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.510s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.510s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.510s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.510s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.587s + 0.002s (eta: 0:06:03)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.553s + 0.002s (eta: 0:05:37)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.538s + 0.002s (eta: 0:05:22)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.527s + 0.002s (eta: 0:05:11)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.518s + 0.003s (eta: 0:05:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.523s + 0.003s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.522s + 0.003s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.520s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.523s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.530s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.530s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.531s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.534s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.530s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.528s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.529s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.530s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.526s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.526s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.528s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.529s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.529s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.528s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.526s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.527s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.528s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.528s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.527s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.526s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.528s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.527s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.526s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.525s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.525s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.524s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.524s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.523s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.522s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.521s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.521s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.522s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.521s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.521s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.522s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.522s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.523s + 0.002s (eta: 0:01:28)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.522s + 0.002s (eta: 0:01:22)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.522s + 0.002s (eta: 0:01:17)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.521s + 0.002s (eta: 0:01:12)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.521s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.521s + 0.002s (eta: 0:01:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.521s + 0.002s (eta: 0:00:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.521s + 0.002s (eta: 0:00:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.521s + 0.002s (eta: 0:00:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.521s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.520s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.518s + 0.002s (eta: 0:00:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.518s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.519s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.519s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.518s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.517s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.756s + 0.002s (eta: 0:07:47)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.495s + 0.002s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.505s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.516s + 0.002s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.510s + 0.002s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.503s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.503s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.501s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.500s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.500s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.505s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.505s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.505s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.504s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.505s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.507s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.508s + 0.002s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.508s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.508s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.507s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.507s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.508s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.508s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.507s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.508s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.507s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.507s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.507s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.507s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.508s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.508s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.508s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.508s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.507s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.506s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.506s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.507s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.508s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.506s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.507s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.506s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.505s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.506s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.506s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.505s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.505s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.504s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.505s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.505s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.504s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.504s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.504s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.504s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.505s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.505s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.506s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.506s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.506s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.506s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.506s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.507s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.507s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.566s + 0.002s (eta: 0:05:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.488s + 0.001s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.475s + 0.001s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.482s + 0.001s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.482s + 0.001s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.489s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.491s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.493s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.502s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.502s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.506s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.508s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.510s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.510s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.509s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.511s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.514s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.517s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.520s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.521s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.521s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.521s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.520s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.517s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.518s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.518s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.518s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.519s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.519s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.519s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.520s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.521s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.521s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.520s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.520s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.520s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.520s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.520s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.521s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.520s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.520s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.520s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.520s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.520s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.519s + 0.002s (eta: 0:01:32)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.519s + 0.002s (eta: 0:01:27)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.520s + 0.002s (eta: 0:01:22)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.521s + 0.002s (eta: 0:01:17)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.521s + 0.002s (eta: 0:01:12)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.522s + 0.002s (eta: 0:01:07)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.521s + 0.002s (eta: 0:01:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.522s + 0.002s (eta: 0:00:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.521s + 0.002s (eta: 0:00:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.521s + 0.002s (eta: 0:00:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.522s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.523s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.523s + 0.002s (eta: 0:00:30)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.523s + 0.002s (eta: 0:00:25)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.522s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.521s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.521s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.519s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.668s + 0.001s (eta: 0:06:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.509s + 0.002s (eta: 0:05:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.520s + 0.002s (eta: 0:05:11)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.521s + 0.001s (eta: 0:05:07)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.519s + 0.002s (eta: 0:05:01)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.515s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.517s + 0.002s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.514s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.508s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.512s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.510s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.513s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.511s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.507s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.509s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.509s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.509s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.508s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.508s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.507s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.505s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.505s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.504s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.504s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.502s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.501s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.499s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.498s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.498s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.498s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.498s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.497s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.498s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.498s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.498s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.498s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.498s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.497s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.497s + 0.002s (eta: 0:01:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.497s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.497s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.497s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.499s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.499s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.499s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.499s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.499s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.499s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.498s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.499s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.499s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.498s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.498s + 0.002s (eta: 0:00:48)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.498s + 0.002s (eta: 0:00:43)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.497s + 0.002s (eta: 0:00:38)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.497s + 0.002s (eta: 0:00:33)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.497s + 0.002s (eta: 0:00:28)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.497s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.497s + 0.002s (eta: 0:00:18)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.497s + 0.002s (eta: 0:00:13)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.497s + 0.002s (eta: 0:00:08)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.497s + 0.002s (eta: 0:00:03)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.680s + 0.002s (eta: 0:07:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.573s + 0.002s (eta: 0:05:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.556s + 0.002s (eta: 0:05:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.538s + 0.002s (eta: 0:05:17)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.530s + 0.002s (eta: 0:05:07)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.528s + 0.002s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.521s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.522s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.525s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.521s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.525s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.523s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.520s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.518s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.519s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.515s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.513s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.512s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.512s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.508s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.507s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.505s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.506s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.504s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.504s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.504s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.504s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.504s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.503s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.503s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.502s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.503s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.502s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.503s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.503s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.502s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.503s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.502s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.503s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.502s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.501s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.501s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.502s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.502s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.501s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.500s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.501s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.500s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.501s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.501s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.500s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.500s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.502s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.502s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.502s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.501s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.501s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.501s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.501s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.501s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.501s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.500s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.638s + 0.002s (eta: 0:06:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.441s + 0.003s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.486s + 0.003s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.511s + 0.002s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.519s + 0.002s (eta: 0:05:01)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.521s + 0.002s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.520s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.522s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.519s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.520s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.523s + 0.003s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.521s + 0.003s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.518s + 0.003s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.517s + 0.003s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.517s + 0.003s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.513s + 0.003s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.511s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.512s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.513s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.513s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.514s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.514s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.513s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.512s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.515s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.516s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.518s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.518s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.520s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.522s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.522s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.524s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.524s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.525s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.525s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.523s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.521s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.522s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.522s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.522s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.522s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.521s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.521s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.522s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.520s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.520s + 0.002s (eta: 0:01:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.521s + 0.002s (eta: 0:01:22)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.520s + 0.002s (eta: 0:01:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.519s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.519s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.519s + 0.002s (eta: 0:01:01)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.518s + 0.002s (eta: 0:00:56)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.518s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.517s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.517s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.517s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.518s + 0.002s (eta: 0:00:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.518s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.518s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.518s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.517s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.515s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step32499.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.603s + 0.001s (eta: 0:06:13)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.521s + 0.001s (eta: 0:05:17)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.507s + 0.001s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.502s + 0.003s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.495s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.505s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.512s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.515s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.512s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.520s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.519s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.518s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.516s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.516s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.514s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.513s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.510s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.513s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.514s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.513s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.515s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.515s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.514s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.515s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.517s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.515s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.516s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.514s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.513s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.513s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.514s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.513s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.512s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.512s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.511s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.511s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.512s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.513s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.513s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.514s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.515s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.514s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.513s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.513s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.512s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.512s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.513s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.513s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.512s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.512s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.512s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.511s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.511s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.511s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.512s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.512s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.512s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.512s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.512s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.512s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.512s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.512s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 339.536s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [1822 1778 1060 ... 1391  151 1301]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.7908
INFO voc_eval.py: 171: [ 322 1000 1399 ...  744 1739 1447]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8204
INFO voc_eval.py: 171: [ 910 1844 1496 ...  977  348 1714]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.7241
INFO voc_eval.py: 171: [2250 3170  129 ...  218  185 2346]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6494
INFO voc_eval.py: 171: [1506 2838  221 ...  435  351 2716]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.6481
INFO voc_eval.py: 171: [ 571 1496 1236 ... 1201  982  447]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.7934
INFO voc_eval.py: 171: [5043 7679 6637 ... 4458 2273 4818]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8601
INFO voc_eval.py: 171: [  79  365  664 ...    4 1327 1391]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8232
INFO voc_eval.py: 171: [ 218  219 5480 ... 8230  268 7905]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6140
INFO voc_eval.py: 171: [1158  689 1157 ...  289  416 1461]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.7771
INFO voc_eval.py: 171: [ 900 1203 2498 ... 1112   97 2350]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.6795
INFO voc_eval.py: 171: [ 131 1294 1270 ... 1805   65 1360]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8082
INFO voc_eval.py: 171: [ 44 549 165 ... 482 291 499]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8205
INFO voc_eval.py: 171: [ 581  322 1865 ...  273 1074  721]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.7817
INFO voc_eval.py: 171: [ 9126 11031 23246 ... 20762  7405  4110]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8284
INFO voc_eval.py: 171: [3942 1537  397 ...  340 3609  456]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.4599
INFO voc_eval.py: 171: [  70  527 1216 ... 1301  285  312]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.7600
INFO voc_eval.py: 171: [1137 1680  416 ... 1584 1345 1612]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7277
INFO voc_eval.py: 171: [ 220 1653   41 ...   72   58 1082]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.7923
INFO voc_eval.py: 171: [ 895  581 1316 ...  620  759  778]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7324
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7446
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.791
INFO voc_dataset_evaluator.py: 134: 0.820
INFO voc_dataset_evaluator.py: 134: 0.724
INFO voc_dataset_evaluator.py: 134: 0.649
INFO voc_dataset_evaluator.py: 134: 0.648
INFO voc_dataset_evaluator.py: 134: 0.793
INFO voc_dataset_evaluator.py: 134: 0.860
INFO voc_dataset_evaluator.py: 134: 0.823
INFO voc_dataset_evaluator.py: 134: 0.614
INFO voc_dataset_evaluator.py: 134: 0.777
INFO voc_dataset_evaluator.py: 134: 0.680
INFO voc_dataset_evaluator.py: 134: 0.808
INFO voc_dataset_evaluator.py: 134: 0.820
INFO voc_dataset_evaluator.py: 134: 0.782
INFO voc_dataset_evaluator.py: 134: 0.828
INFO voc_dataset_evaluator.py: 134: 0.460
INFO voc_dataset_evaluator.py: 134: 0.760
INFO voc_dataset_evaluator.py: 134: 0.728
INFO voc_dataset_evaluator.py: 134: 0.792
INFO voc_dataset_evaluator.py: 134: 0.732
INFO voc_dataset_evaluator.py: 135: 0.745
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
Start testing on iteration 34999
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.12s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.564s + 0.001s (eta: 0:05:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.504s + 0.002s (eta: 0:05:07)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.514s + 0.002s (eta: 0:05:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.504s + 0.002s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.512s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.515s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.516s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.519s + 0.002s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.516s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.512s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.506s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.511s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.512s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.515s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.515s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.516s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.518s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.520s + 0.002s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.523s + 0.002s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.522s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.522s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.522s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.522s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.522s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.522s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.522s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.520s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.518s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.518s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.517s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.516s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.517s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.515s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.516s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.516s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.516s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.517s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.517s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.520s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.519s + 0.002s (eta: 0:01:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.518s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.517s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.517s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.515s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.515s + 0.002s (eta: 0:01:32)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.516s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.515s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.515s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.515s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.515s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.514s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.514s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.514s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.513s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.513s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.513s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.513s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.513s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.512s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.512s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.512s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.512s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.558s + 0.001s (eta: 0:05:45)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.499s + 0.002s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.498s + 0.002s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.517s + 0.001s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.523s + 0.001s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.523s + 0.002s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.530s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.532s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.527s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.522s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.524s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.519s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.519s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.520s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.524s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.526s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.526s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.524s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.523s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.520s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.521s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.520s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.522s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.523s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.523s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.523s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.521s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.521s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.521s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.521s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.521s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.521s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.522s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.522s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.522s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.522s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.523s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.522s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.521s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.521s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.521s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.522s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.522s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.523s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.522s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.522s + 0.002s (eta: 0:01:28)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.523s + 0.002s (eta: 0:01:22)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.522s + 0.002s (eta: 0:01:17)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.522s + 0.002s (eta: 0:01:12)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.522s + 0.002s (eta: 0:01:07)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.522s + 0.002s (eta: 0:01:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.521s + 0.002s (eta: 0:00:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.522s + 0.002s (eta: 0:00:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.522s + 0.002s (eta: 0:00:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.522s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.522s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.522s + 0.002s (eta: 0:00:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.523s + 0.002s (eta: 0:00:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.523s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.523s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.522s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.519s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.532s + 0.001s (eta: 0:05:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.474s + 0.001s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.496s + 0.002s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.502s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.490s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.494s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.501s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.503s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.501s + 0.003s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.503s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.508s + 0.003s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.510s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.508s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.509s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.508s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.508s + 0.002s (eta: 0:03:58)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.507s + 0.002s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.507s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.507s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.508s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.507s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.505s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.504s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.506s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.505s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.505s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.505s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.505s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.505s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.505s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.505s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.504s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.503s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.502s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.503s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.502s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.502s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.502s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.502s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.502s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.503s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.502s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.502s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.503s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.502s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.503s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.504s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.504s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.505s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.504s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.504s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.503s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.504s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.504s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.504s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.504s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.505s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.504s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.504s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.504s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.504s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.504s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.560s + 0.001s (eta: 0:05:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.477s + 0.003s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.510s + 0.002s (eta: 0:05:06)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.505s + 0.002s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.504s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.507s + 0.002s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.512s + 0.003s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.508s + 0.003s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.506s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.502s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.503s + 0.003s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.502s + 0.003s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.500s + 0.003s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.502s + 0.003s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.502s + 0.003s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.502s + 0.003s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.503s + 0.003s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.504s + 0.003s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.503s + 0.003s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.504s + 0.003s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.505s + 0.003s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.507s + 0.003s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.506s + 0.003s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.508s + 0.003s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.510s + 0.003s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.509s + 0.003s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.510s + 0.003s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.509s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.511s + 0.003s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.510s + 0.003s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.509s + 0.003s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.509s + 0.003s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.510s + 0.003s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.510s + 0.003s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.511s + 0.003s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.510s + 0.003s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.511s + 0.003s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.511s + 0.003s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.511s + 0.003s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.511s + 0.003s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.512s + 0.003s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.513s + 0.003s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.513s + 0.003s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.513s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.513s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.513s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.513s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.512s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.513s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.512s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.512s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.512s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.513s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.513s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.513s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.513s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.513s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.512s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.512s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.512s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.512s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.511s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.584s + 0.001s (eta: 0:06:01)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.505s + 0.001s (eta: 0:05:07)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.496s + 0.001s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.501s + 0.002s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.515s + 0.002s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.515s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.511s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.509s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.511s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.507s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.507s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.510s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.513s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.517s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.518s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.519s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.515s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.517s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.513s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.513s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.511s + 0.002s (eta: 0:03:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.513s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.513s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.514s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.513s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.513s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.513s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.513s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.513s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.513s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.512s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.511s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.510s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.511s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.510s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.511s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.510s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.510s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.509s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.510s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.509s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.508s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.508s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.509s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.509s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.509s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.509s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.510s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.510s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.510s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.510s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.509s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.509s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.509s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.508s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.508s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.508s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.508s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.509s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.508s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.714s + 0.001s (eta: 0:07:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.536s + 0.002s (eta: 0:05:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.498s + 0.001s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.525s + 0.001s (eta: 0:05:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.519s + 0.001s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.518s + 0.001s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.515s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.519s + 0.002s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.514s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.518s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.518s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.519s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.525s + 0.002s (eta: 0:04:22)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.522s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.523s + 0.002s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.523s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.523s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.524s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.525s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.523s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.523s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.521s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.519s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.521s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.519s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.518s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.520s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.522s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.522s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.520s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.520s + 0.002s (eta: 0:02:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.519s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.519s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.519s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.520s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.520s + 0.002s (eta: 0:02:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.519s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.519s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.521s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.521s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.520s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.521s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.522s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.523s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.523s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.523s + 0.002s (eta: 0:01:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.523s + 0.002s (eta: 0:01:22)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.522s + 0.002s (eta: 0:01:17)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.521s + 0.002s (eta: 0:01:12)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.520s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.521s + 0.002s (eta: 0:01:01)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.521s + 0.002s (eta: 0:00:56)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.521s + 0.002s (eta: 0:00:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.521s + 0.002s (eta: 0:00:46)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.521s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.521s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.521s + 0.002s (eta: 0:00:30)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.521s + 0.002s (eta: 0:00:25)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.521s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.522s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.521s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.518s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.571s + 0.001s (eta: 0:05:53)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.542s + 0.001s (eta: 0:05:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.530s + 0.002s (eta: 0:05:18)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.520s + 0.002s (eta: 0:05:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.528s + 0.002s (eta: 0:05:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.537s + 0.002s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.534s + 0.002s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.536s + 0.002s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.534s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.533s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.532s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.524s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.521s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.517s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.513s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.514s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.512s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.512s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.510s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.512s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.513s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.510s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.509s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.508s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.508s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.508s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.507s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.506s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.505s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.505s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.505s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.507s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.507s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.506s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.506s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.506s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.505s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.504s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.505s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.504s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.504s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.504s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.505s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.505s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.506s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.506s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.504s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.505s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.505s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.506s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.506s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.506s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.506s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.507s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.507s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.507s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.507s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.509s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.509s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.509s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.510s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step34999.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.623s + 0.002s (eta: 0:06:26)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.533s + 0.002s (eta: 0:05:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.513s + 0.002s (eta: 0:05:07)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.502s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.488s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.487s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.493s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.496s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.495s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.497s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.502s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.503s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.501s + 0.002s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.502s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.501s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.503s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.506s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.507s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.507s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.505s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.505s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.509s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.508s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.506s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.506s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.505s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.506s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.507s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.507s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.507s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.508s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.509s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.509s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.510s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.510s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.509s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.509s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.508s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.508s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.507s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.506s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.507s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.507s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.506s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.506s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.505s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.506s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.505s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.504s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.504s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.505s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.506s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.505s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.505s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.505s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.505s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.505s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.506s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.505s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.505s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.505s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.504s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 339.460s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [1826 1781 1061 ... 1394  906  783]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.7912
INFO voc_eval.py: 171: [1005  325 1400 ... 1448  445  939]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8206
INFO voc_eval.py: 171: [ 915 1502 1851 ...  973  971  325]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.7234
INFO voc_eval.py: 171: [2249 3169  129 ... 2928 1257 3088]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6483
INFO voc_eval.py: 171: [1503  220 2838 ... 3486 1888  679]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.6475
INFO voc_eval.py: 171: [ 569  144 1235 ...  574  204  952]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.7937
INFO voc_eval.py: 171: [6644 4984 7687 ... 3084  127 7546]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8602
INFO voc_eval.py: 171: [  79  664  365 ... 1328 1479 1392]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8233
INFO voc_eval.py: 171: [ 221  222 5472 ... 1621  785 9864]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6134
INFO voc_eval.py: 171: [1157  689 1156 ...  477 1492 1459]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.7768
INFO voc_eval.py: 171: [ 904 1206 2497 ...  768 1162 1207]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.6791
INFO voc_eval.py: 171: [1294  131 1270 ... 1068 1357 1297]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8081
INFO voc_eval.py: 171: [  44  165  548 ... 1050  482  499]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8206
INFO voc_eval.py: 171: [ 584 1870  323 ...  293  273 1720]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.7819
INFO voc_eval.py: 171: [23247 11028  9123 ...  6129  3346  5503]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8285
INFO voc_eval.py: 171: [3935  397 1539 ... 1052 1100 2267]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.4592
INFO voc_eval.py: 171: [  70  530 1220 ... 1483 1689  637]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.7601
INFO voc_eval.py: 171: [1137 1682  416 ... 1317  648 1585]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7271
INFO voc_eval.py: 171: [ 220 1650   41 ... 1342  230 1495]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.7922
INFO voc_eval.py: 171: [ 893 1313  581 ...  933  739  309]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7324
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7444
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.791
INFO voc_dataset_evaluator.py: 134: 0.821
INFO voc_dataset_evaluator.py: 134: 0.723
INFO voc_dataset_evaluator.py: 134: 0.648
INFO voc_dataset_evaluator.py: 134: 0.647
INFO voc_dataset_evaluator.py: 134: 0.794
INFO voc_dataset_evaluator.py: 134: 0.860
INFO voc_dataset_evaluator.py: 134: 0.823
INFO voc_dataset_evaluator.py: 134: 0.613
INFO voc_dataset_evaluator.py: 134: 0.777
INFO voc_dataset_evaluator.py: 134: 0.679
INFO voc_dataset_evaluator.py: 134: 0.808
INFO voc_dataset_evaluator.py: 134: 0.821
INFO voc_dataset_evaluator.py: 134: 0.782
INFO voc_dataset_evaluator.py: 134: 0.829
INFO voc_dataset_evaluator.py: 134: 0.459
INFO voc_dataset_evaluator.py: 134: 0.760
INFO voc_dataset_evaluator.py: 134: 0.727
INFO voc_dataset_evaluator.py: 134: 0.792
INFO voc_dataset_evaluator.py: 134: 0.732
INFO voc_dataset_evaluator.py: 135: 0.744
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
Start testing on iteration 37499
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.735s + 0.002s (eta: 0:07:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.547s + 0.003s (eta: 0:05:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.526s + 0.002s (eta: 0:05:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.522s + 0.002s (eta: 0:05:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.518s + 0.002s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.520s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.519s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.520s + 0.002s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.519s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.517s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.521s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.520s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.526s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.527s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.530s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.530s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.531s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.528s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.527s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.525s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.524s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.522s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.524s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.525s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.529s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.529s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.529s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.528s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.528s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.528s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.527s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.528s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.527s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.528s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.527s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.527s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.527s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.527s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.527s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.526s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.526s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.525s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.524s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.523s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.523s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.523s + 0.002s (eta: 0:01:28)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.522s + 0.002s (eta: 0:01:22)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.522s + 0.002s (eta: 0:01:17)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.522s + 0.002s (eta: 0:01:12)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.521s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.521s + 0.002s (eta: 0:01:01)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.521s + 0.002s (eta: 0:00:56)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.520s + 0.002s (eta: 0:00:51)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.520s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.520s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.520s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.521s + 0.002s (eta: 0:00:30)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.520s + 0.002s (eta: 0:00:25)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.521s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.521s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.521s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.519s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.740s + 0.001s (eta: 0:07:38)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.519s + 0.002s (eta: 0:05:16)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.500s + 0.002s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.512s + 0.002s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.514s + 0.002s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.509s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.504s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.502s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.505s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.514s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.519s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.518s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.516s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.516s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.514s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.512s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.511s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.512s + 0.002s (eta: 0:03:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.511s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.512s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.512s + 0.002s (eta: 0:03:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.513s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.514s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.513s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.513s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.514s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.515s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.513s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.514s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.512s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.512s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.512s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.513s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.512s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.512s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.513s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.513s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.512s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.511s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.511s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.510s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.509s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.510s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.510s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.510s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.510s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.510s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.510s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.509s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.508s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.508s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.507s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.507s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.508s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.509s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.508s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.508s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.508s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.508s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.631s + 0.002s (eta: 0:06:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.497s + 0.001s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.488s + 0.003s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.498s + 0.003s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.497s + 0.003s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.501s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.495s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.496s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.498s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.496s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.497s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.498s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.499s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.499s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.503s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.503s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.506s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.509s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.510s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.509s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.507s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.506s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.506s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.505s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.507s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.505s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.505s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.507s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.507s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.508s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.507s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.507s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.506s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.506s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.505s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.505s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.505s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.505s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.506s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.506s + 0.002s (eta: 0:01:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.506s + 0.002s (eta: 0:01:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.507s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.507s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.507s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.507s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.507s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.506s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.508s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.507s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.507s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.508s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.509s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.509s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.510s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.510s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.510s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.510s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.510s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.510s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.510s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.510s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.509s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.603s + 0.001s (eta: 0:06:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.519s + 0.004s (eta: 0:05:17)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.520s + 0.003s (eta: 0:05:12)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.497s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.488s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.489s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.493s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.497s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.493s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.499s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.501s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.500s + 0.002s (eta: 0:04:15)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.497s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.500s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.502s + 0.002s (eta: 0:04:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.502s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.502s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.506s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.507s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.509s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.511s + 0.002s (eta: 0:03:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.512s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.513s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.514s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.514s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.513s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.516s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.517s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.517s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.517s + 0.002s (eta: 0:02:50)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.517s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.517s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.517s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.517s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.516s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.515s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.515s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.515s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.514s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.514s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.515s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.515s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.514s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.515s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.514s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.514s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.513s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.513s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.512s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.511s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.510s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.510s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.510s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.509s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.509s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.509s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.509s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.509s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.508s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.509s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.510s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.509s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.541s + 0.001s (eta: 0:05:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.516s + 0.001s (eta: 0:05:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.506s + 0.001s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.495s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.497s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.501s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.503s + 0.002s (eta: 0:04:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.503s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.498s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.499s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.500s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.503s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.504s + 0.002s (eta: 0:04:11)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.504s + 0.002s (eta: 0:04:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.504s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.503s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.504s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.504s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.502s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.504s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.505s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.503s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.504s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.504s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.503s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.504s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.503s + 0.002s (eta: 0:03:00)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.504s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.506s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.504s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.503s + 0.002s (eta: 0:02:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.503s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.504s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.504s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.504s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.504s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.506s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.506s + 0.002s (eta: 0:02:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.507s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.507s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.507s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.507s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.507s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.508s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.507s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.508s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.507s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.507s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.509s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.510s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.509s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.509s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.508s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.508s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.509s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.509s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.509s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.508s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.508s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.507s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.549s + 0.001s (eta: 0:05:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.469s + 0.001s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.478s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.493s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.499s + 0.002s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.498s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.499s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.501s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.497s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.493s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.496s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.496s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.495s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.495s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.493s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.495s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.495s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.494s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.493s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.493s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.495s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.496s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.495s + 0.002s (eta: 0:03:17)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.494s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.494s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.494s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.495s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.494s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.493s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.495s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.495s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.494s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.495s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.494s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.495s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.495s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.495s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.495s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.495s + 0.002s (eta: 0:01:58)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.494s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.495s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.495s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.495s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.495s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.494s + 0.002s (eta: 0:01:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.494s + 0.002s (eta: 0:01:23)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.494s + 0.002s (eta: 0:01:18)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.494s + 0.002s (eta: 0:01:13)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.495s + 0.002s (eta: 0:01:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.495s + 0.002s (eta: 0:01:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.496s + 0.002s (eta: 0:00:58)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.496s + 0.002s (eta: 0:00:53)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.496s + 0.002s (eta: 0:00:48)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.496s + 0.002s (eta: 0:00:43)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.495s + 0.002s (eta: 0:00:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.496s + 0.002s (eta: 0:00:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.495s + 0.002s (eta: 0:00:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.495s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.495s + 0.002s (eta: 0:00:18)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.495s + 0.002s (eta: 0:00:13)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.495s + 0.002s (eta: 0:00:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.495s + 0.002s (eta: 0:00:03)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.625s + 0.002s (eta: 0:06:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.533s + 0.002s (eta: 0:05:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.527s + 0.002s (eta: 0:05:15)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.532s + 0.002s (eta: 0:05:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.529s + 0.002s (eta: 0:05:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.532s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.532s + 0.002s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.530s + 0.002s (eta: 0:04:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.526s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.531s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.528s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.532s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.536s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.530s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.529s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.530s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.528s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.527s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.525s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.525s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.524s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.523s + 0.002s (eta: 0:03:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.524s + 0.002s (eta: 0:03:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.525s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.526s + 0.002s (eta: 0:03:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.524s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.525s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.525s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.525s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.525s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.524s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.523s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.522s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.523s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.524s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.523s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.525s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.524s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.523s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.523s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.522s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.521s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.521s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.521s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.520s + 0.002s (eta: 0:01:32)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.520s + 0.002s (eta: 0:01:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.519s + 0.002s (eta: 0:01:22)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.518s + 0.002s (eta: 0:01:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.519s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.519s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.519s + 0.002s (eta: 0:01:01)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.519s + 0.002s (eta: 0:00:56)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.520s + 0.002s (eta: 0:00:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.520s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.520s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.520s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.521s + 0.002s (eta: 0:00:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.520s + 0.002s (eta: 0:00:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.520s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.520s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.520s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.518s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.11s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step37499.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.620s + 0.002s (eta: 0:06:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.544s + 0.001s (eta: 0:05:31)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.538s + 0.001s (eta: 0:05:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.532s + 0.002s (eta: 0:05:13)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.543s + 0.002s (eta: 0:05:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.543s + 0.002s (eta: 0:05:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.538s + 0.002s (eta: 0:05:01)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.537s + 0.002s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.529s + 0.002s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.529s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.529s + 0.002s (eta: 0:04:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.527s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.529s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.531s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.529s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.531s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.532s + 0.002s (eta: 0:04:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.534s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.534s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.535s + 0.002s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.534s + 0.002s (eta: 0:03:43)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.533s + 0.002s (eta: 0:03:38)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.534s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.535s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.533s + 0.002s (eta: 0:03:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.530s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.530s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.530s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.529s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.529s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.529s + 0.002s (eta: 0:02:48)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.528s + 0.002s (eta: 0:02:43)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.528s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.527s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.527s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.525s + 0.002s (eta: 0:02:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.524s + 0.002s (eta: 0:02:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.524s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.522s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.521s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.522s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.521s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.520s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.520s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.521s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.521s + 0.002s (eta: 0:01:27)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.521s + 0.002s (eta: 0:01:22)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.520s + 0.002s (eta: 0:01:17)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.521s + 0.002s (eta: 0:01:12)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.520s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.521s + 0.002s (eta: 0:01:01)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.521s + 0.002s (eta: 0:00:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.521s + 0.002s (eta: 0:00:51)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.520s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.521s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.520s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.520s + 0.002s (eta: 0:00:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.520s + 0.002s (eta: 0:00:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.519s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.520s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.519s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.517s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 338.908s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [1824 1779 1063 ... 1263  487 1791]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.7911
INFO voc_eval.py: 171: [ 325 1006 1402 ... 1014 1510  987]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8206
INFO voc_eval.py: 171: [ 915 1505 1855 ... 1347 1587  679]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.7225
INFO voc_eval.py: 171: [2254 3174  129 ... 1197 2932  873]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6481
INFO voc_eval.py: 171: [1508  219 2844 ...  881 2037  152]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.6473
INFO voc_eval.py: 171: [ 569 1233 1492 ...  101  204 1041]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.7940
INFO voc_eval.py: 171: [6666 5004 7712 ...  946 2784 5882]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8600
INFO voc_eval.py: 171: [ 365  665   79 ... 1481  772    4]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8229
INFO voc_eval.py: 171: [ 218  219  613 ... 5616 9394 4846]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6140
INFO voc_eval.py: 171: [1162  692 1161 ...  254  302  479]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.7766
INFO voc_eval.py: 171: [ 906 1210 2501 ... 1248 2182 2060]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.6781
INFO voc_eval.py: 171: [ 131 1295 1271 ... 1154  613  658]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8077
INFO voc_eval.py: 171: [  45  167  551 ... 1684 1711  755]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8203
INFO voc_eval.py: 171: [ 584 1868  323 ... 1638  293  313]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.7824
INFO voc_eval.py: 171: [ 9135 11037  7027 ... 17271  9805 17352]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8283
INFO voc_eval.py: 171: [3930 1537  398 ... 2323 2439 1053]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.4584
INFO voc_eval.py: 171: [  70  535 1225 ... 1527 1571   73]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.7594
INFO voc_eval.py: 171: [1141 1688  420 ...   59  194 1990]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7278
INFO voc_eval.py: 171: [ 220 1653   41 ...  611   40  282]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.7920
INFO voc_eval.py: 171: [ 893  529  584 ...  311 1514  103]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7320
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7442
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.791
INFO voc_dataset_evaluator.py: 134: 0.821
INFO voc_dataset_evaluator.py: 134: 0.722
INFO voc_dataset_evaluator.py: 134: 0.648
INFO voc_dataset_evaluator.py: 134: 0.647
INFO voc_dataset_evaluator.py: 134: 0.794
INFO voc_dataset_evaluator.py: 134: 0.860
INFO voc_dataset_evaluator.py: 134: 0.823
INFO voc_dataset_evaluator.py: 134: 0.614
INFO voc_dataset_evaluator.py: 134: 0.777
INFO voc_dataset_evaluator.py: 134: 0.678
INFO voc_dataset_evaluator.py: 134: 0.808
INFO voc_dataset_evaluator.py: 134: 0.820
INFO voc_dataset_evaluator.py: 134: 0.782
INFO voc_dataset_evaluator.py: 134: 0.828
INFO voc_dataset_evaluator.py: 134: 0.458
INFO voc_dataset_evaluator.py: 134: 0.759
INFO voc_dataset_evaluator.py: 134: 0.728
INFO voc_dataset_evaluator.py: 134: 0.792
INFO voc_dataset_evaluator.py: 134: 0.732
INFO voc_dataset_evaluator.py: 135: 0.744
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
Start testing on iteration 39999
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='configs/dt/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC.yaml', dataset='voc2007', load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth', load_detectron=None, multi_gpu_testing=True, num_classes=None, output_dir=None, range=None, set_cfgs=[], vis=False)
INFO test_net.py:  83: Automatically set output directory to Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO subprocess.py:  59: 0,1,2,3,4,5,6,7
INFO subprocess.py:  67: gpu_inds: [0, 1, 2, 3, 4, 5, 6, 7]
INFO subprocess.py:  89: detection range command 0: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 0 619 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO subprocess.py:  89: detection range command 1: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 619 1238 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO subprocess.py:  89: detection range command 2: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1238 1857 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO subprocess.py:  89: detection range command 3: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 1857 2476 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO subprocess.py:  89: detection range command 4: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 2476 3095 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO subprocess.py:  89: detection range command 5: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3095 3714 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO subprocess.py:  89: detection range command 6: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 3714 4333 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO subprocess.py:  89: detection range command 7: python /home/ubuntu/Detectron.pytorch/tools/test_net.py --range 4333 4952 --cfg Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml --set TEST.DATASETS '("voc_2007_test",)' --output_dir Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test --load_ckpt Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 0 with range [1, 619]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[0, 619], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 1/619 0.566s + 0.001s (eta: 0:05:50)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 11/619 0.497s + 0.001s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 21/619 0.514s + 0.002s (eta: 0:05:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 31/619 0.517s + 0.002s (eta: 0:05:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 41/619 0.514s + 0.002s (eta: 0:04:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 51/619 0.513s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 61/619 0.516s + 0.002s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 71/619 0.514s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 81/619 0.513s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 91/619 0.510s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 101/619 0.510s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 111/619 0.509s + 0.002s (eta: 0:04:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 121/619 0.508s + 0.002s (eta: 0:04:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 131/619 0.508s + 0.002s (eta: 0:04:09)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 141/619 0.507s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 151/619 0.506s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 161/619 0.506s + 0.002s (eta: 0:03:52)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 171/619 0.506s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 181/619 0.505s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 191/619 0.504s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 201/619 0.503s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 211/619 0.503s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 221/619 0.502s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 231/619 0.501s + 0.002s (eta: 0:03:15)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 241/619 0.505s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 251/619 0.503s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 261/619 0.500s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 271/619 0.500s + 0.002s (eta: 0:02:54)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 281/619 0.500s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 291/619 0.499s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 301/619 0.499s + 0.002s (eta: 0:02:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 311/619 0.499s + 0.002s (eta: 0:02:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 321/619 0.498s + 0.002s (eta: 0:02:28)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 331/619 0.497s + 0.002s (eta: 0:02:23)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 341/619 0.495s + 0.002s (eta: 0:02:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 351/619 0.494s + 0.002s (eta: 0:02:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 361/619 0.495s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 371/619 0.496s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 381/619 0.496s + 0.002s (eta: 0:01:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 391/619 0.497s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 401/619 0.497s + 0.002s (eta: 0:01:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 411/619 0.498s + 0.002s (eta: 0:01:44)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 421/619 0.499s + 0.002s (eta: 0:01:39)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 431/619 0.500s + 0.002s (eta: 0:01:34)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 441/619 0.500s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 451/619 0.500s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 461/619 0.498s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 471/619 0.497s + 0.002s (eta: 0:01:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 481/619 0.497s + 0.002s (eta: 0:01:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 491/619 0.496s + 0.002s (eta: 0:01:03)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 501/619 0.497s + 0.002s (eta: 0:00:58)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 511/619 0.496s + 0.002s (eta: 0:00:53)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 521/619 0.496s + 0.002s (eta: 0:00:48)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 531/619 0.495s + 0.002s (eta: 0:00:43)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 541/619 0.495s + 0.002s (eta: 0:00:38)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 551/619 0.495s + 0.002s (eta: 0:00:33)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 561/619 0.495s + 0.002s (eta: 0:00:28)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 571/619 0.494s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 581/619 0.495s + 0.002s (eta: 0:00:18)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 591/619 0.496s + 0.002s (eta: 0:00:13)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 601/619 0.496s + 0.002s (eta: 0:00:08)
INFO test_engine.py: 281: im_detect: range [1, 619] of 4952: 611/619 0.496s + 0.002s (eta: 0:00:03)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_0_619.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 1 with range [620, 1238]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[619, 1238], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 620/1238 0.687s + 0.001s (eta: 0:07:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 630/1238 0.524s + 0.002s (eta: 0:05:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 640/1238 0.521s + 0.001s (eta: 0:05:12)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 650/1238 0.525s + 0.002s (eta: 0:05:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 660/1238 0.525s + 0.002s (eta: 0:05:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 670/1238 0.520s + 0.002s (eta: 0:04:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 680/1238 0.518s + 0.002s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 690/1238 0.519s + 0.002s (eta: 0:04:45)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 700/1238 0.520s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 710/1238 0.519s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 720/1238 0.519s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 730/1238 0.521s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 740/1238 0.522s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 750/1238 0.520s + 0.002s (eta: 0:04:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 760/1238 0.518s + 0.002s (eta: 0:04:08)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 770/1238 0.518s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 780/1238 0.516s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 790/1238 0.518s + 0.002s (eta: 0:03:53)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 800/1238 0.516s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 810/1238 0.516s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 820/1238 0.514s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 830/1238 0.513s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 840/1238 0.514s + 0.002s (eta: 0:03:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 850/1238 0.514s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 860/1238 0.513s + 0.002s (eta: 0:03:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 870/1238 0.513s + 0.002s (eta: 0:03:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 880/1238 0.513s + 0.002s (eta: 0:03:04)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 890/1238 0.512s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 900/1238 0.511s + 0.002s (eta: 0:02:53)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 910/1238 0.509s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 920/1238 0.510s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 930/1238 0.509s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 940/1238 0.511s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 950/1238 0.511s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 960/1238 0.510s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 970/1238 0.510s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 980/1238 0.511s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 990/1238 0.510s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1000/1238 0.510s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1010/1238 0.509s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1020/1238 0.509s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1030/1238 0.509s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1040/1238 0.509s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1050/1238 0.508s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1060/1238 0.507s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1070/1238 0.507s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1080/1238 0.507s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1090/1238 0.507s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1100/1238 0.507s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1110/1238 0.506s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1120/1238 0.506s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1130/1238 0.507s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1140/1238 0.507s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1150/1238 0.508s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1160/1238 0.507s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1170/1238 0.507s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1180/1238 0.507s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1190/1238 0.507s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1200/1238 0.507s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1210/1238 0.507s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1220/1238 0.507s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [620, 1238] of 4952: 1230/1238 0.506s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_619_1238.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 2 with range [1239, 1857]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1238, 1857], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1239/1857 0.549s + 0.001s (eta: 0:05:40)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1249/1857 0.530s + 0.002s (eta: 0:05:23)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1259/1857 0.525s + 0.002s (eta: 0:05:14)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1269/1857 0.512s + 0.001s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1279/1857 0.506s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1289/1857 0.507s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1299/1857 0.506s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1309/1857 0.508s + 0.002s (eta: 0:04:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1319/1857 0.500s + 0.002s (eta: 0:04:30)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1329/1857 0.502s + 0.002s (eta: 0:04:26)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1339/1857 0.501s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1349/1857 0.503s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1359/1857 0.505s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1369/1857 0.505s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1379/1857 0.506s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1389/1857 0.505s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1399/1857 0.503s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1409/1857 0.502s + 0.002s (eta: 0:03:45)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1419/1857 0.500s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1429/1857 0.497s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1439/1857 0.496s + 0.002s (eta: 0:03:28)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1449/1857 0.497s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1459/1857 0.496s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1469/1857 0.495s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1479/1857 0.492s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1489/1857 0.493s + 0.002s (eta: 0:03:02)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1499/1857 0.494s + 0.002s (eta: 0:02:57)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1509/1857 0.493s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1519/1857 0.493s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1529/1857 0.492s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1539/1857 0.491s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1549/1857 0.491s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1559/1857 0.492s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1569/1857 0.491s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1579/1857 0.491s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1589/1857 0.491s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1599/1857 0.491s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1609/1857 0.491s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1619/1857 0.492s + 0.002s (eta: 0:01:57)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1629/1857 0.493s + 0.002s (eta: 0:01:52)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1639/1857 0.492s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1649/1857 0.492s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1659/1857 0.492s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1669/1857 0.492s + 0.002s (eta: 0:01:32)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1679/1857 0.491s + 0.002s (eta: 0:01:27)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1689/1857 0.492s + 0.002s (eta: 0:01:22)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1699/1857 0.492s + 0.002s (eta: 0:01:18)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1709/1857 0.492s + 0.002s (eta: 0:01:13)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1719/1857 0.493s + 0.002s (eta: 0:01:08)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1729/1857 0.493s + 0.002s (eta: 0:01:03)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1739/1857 0.493s + 0.002s (eta: 0:00:58)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1749/1857 0.492s + 0.002s (eta: 0:00:53)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1759/1857 0.491s + 0.002s (eta: 0:00:48)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1769/1857 0.492s + 0.002s (eta: 0:00:43)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1779/1857 0.492s + 0.002s (eta: 0:00:38)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1789/1857 0.492s + 0.002s (eta: 0:00:33)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1799/1857 0.491s + 0.002s (eta: 0:00:28)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1809/1857 0.492s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1819/1857 0.491s + 0.002s (eta: 0:00:18)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1829/1857 0.491s + 0.002s (eta: 0:00:13)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1839/1857 0.492s + 0.002s (eta: 0:00:08)
INFO test_engine.py: 281: im_detect: range [1239, 1857] of 4952: 1849/1857 0.492s + 0.002s (eta: 0:00:03)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1238_1857.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 3 with range [1858, 2476]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[1857, 2476], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1858/2476 0.609s + 0.002s (eta: 0:06:17)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1868/2476 0.512s + 0.001s (eta: 0:05:12)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1878/2476 0.519s + 0.003s (eta: 0:05:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1888/2476 0.513s + 0.002s (eta: 0:05:02)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1898/2476 0.509s + 0.002s (eta: 0:04:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1908/2476 0.506s + 0.002s (eta: 0:04:48)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1918/2476 0.508s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1928/2476 0.510s + 0.002s (eta: 0:04:40)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1938/2476 0.512s + 0.002s (eta: 0:04:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1948/2476 0.509s + 0.002s (eta: 0:04:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1958/2476 0.507s + 0.002s (eta: 0:04:23)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1968/2476 0.506s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1978/2476 0.501s + 0.002s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1988/2476 0.505s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 1998/2476 0.505s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2008/2476 0.503s + 0.002s (eta: 0:03:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2018/2476 0.500s + 0.002s (eta: 0:03:49)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2028/2476 0.504s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2038/2476 0.503s + 0.002s (eta: 0:03:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2048/2476 0.505s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2058/2476 0.505s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2068/2476 0.507s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2078/2476 0.506s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2088/2476 0.504s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2098/2476 0.505s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2108/2476 0.505s + 0.002s (eta: 0:03:06)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2118/2476 0.505s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2128/2476 0.505s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2138/2476 0.506s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2148/2476 0.507s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2158/2476 0.507s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2168/2476 0.506s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2178/2476 0.508s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2188/2476 0.509s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2198/2476 0.509s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2208/2476 0.510s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2218/2476 0.509s + 0.002s (eta: 0:02:11)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2228/2476 0.511s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2238/2476 0.511s + 0.002s (eta: 0:02:02)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2248/2476 0.511s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2258/2476 0.511s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2268/2476 0.511s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2278/2476 0.513s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2288/2476 0.512s + 0.002s (eta: 0:01:36)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2298/2476 0.511s + 0.002s (eta: 0:01:31)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2308/2476 0.511s + 0.002s (eta: 0:01:26)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2318/2476 0.511s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2328/2476 0.511s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2338/2476 0.510s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2348/2476 0.510s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2358/2476 0.511s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2368/2476 0.510s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2378/2476 0.511s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2388/2476 0.510s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2398/2476 0.510s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2408/2476 0.510s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2418/2476 0.510s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2428/2476 0.510s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2438/2476 0.510s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2448/2476 0.510s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2458/2476 0.509s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [1858, 2476] of 4952: 2468/2476 0.508s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_1857_2476.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 4 with range [2477, 3095]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[2476, 3095], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.10s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2477/3095 0.783s + 0.002s (eta: 0:08:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2487/3095 0.541s + 0.001s (eta: 0:05:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2497/3095 0.539s + 0.002s (eta: 0:05:23)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2507/3095 0.534s + 0.002s (eta: 0:05:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2517/3095 0.530s + 0.002s (eta: 0:05:07)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2527/3095 0.532s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2537/3095 0.537s + 0.002s (eta: 0:05:00)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2547/3095 0.536s + 0.002s (eta: 0:04:54)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2557/3095 0.532s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2567/3095 0.532s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2577/3095 0.534s + 0.002s (eta: 0:04:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2587/3095 0.532s + 0.002s (eta: 0:04:31)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2597/3095 0.529s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2607/3095 0.528s + 0.002s (eta: 0:04:18)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2617/3095 0.526s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2627/3095 0.528s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2637/3095 0.529s + 0.002s (eta: 0:04:02)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2647/3095 0.528s + 0.002s (eta: 0:03:57)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2657/3095 0.527s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2667/3095 0.527s + 0.002s (eta: 0:03:46)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2677/3095 0.525s + 0.002s (eta: 0:03:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2687/3095 0.525s + 0.002s (eta: 0:03:35)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2697/3095 0.526s + 0.002s (eta: 0:03:30)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2707/3095 0.525s + 0.002s (eta: 0:03:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2717/3095 0.523s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2727/3095 0.525s + 0.002s (eta: 0:03:13)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2737/3095 0.525s + 0.002s (eta: 0:03:08)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2747/3095 0.525s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2757/3095 0.525s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2767/3095 0.524s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2777/3095 0.523s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2787/3095 0.523s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2797/3095 0.523s + 0.002s (eta: 0:02:36)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2807/3095 0.522s + 0.002s (eta: 0:02:30)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2817/3095 0.521s + 0.002s (eta: 0:02:25)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2827/3095 0.521s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2837/3095 0.520s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2847/3095 0.520s + 0.002s (eta: 0:02:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2857/3095 0.520s + 0.002s (eta: 0:02:04)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2867/3095 0.520s + 0.002s (eta: 0:01:59)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2877/3095 0.519s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2887/3095 0.517s + 0.002s (eta: 0:01:47)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2897/3095 0.517s + 0.002s (eta: 0:01:42)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2907/3095 0.518s + 0.002s (eta: 0:01:37)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2917/3095 0.518s + 0.002s (eta: 0:01:32)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2927/3095 0.517s + 0.002s (eta: 0:01:27)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2937/3095 0.517s + 0.002s (eta: 0:01:21)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2947/3095 0.516s + 0.002s (eta: 0:01:16)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2957/3095 0.516s + 0.002s (eta: 0:01:11)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2967/3095 0.516s + 0.002s (eta: 0:01:06)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2977/3095 0.516s + 0.002s (eta: 0:01:01)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2987/3095 0.516s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 2997/3095 0.516s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3007/3095 0.515s + 0.002s (eta: 0:00:45)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3017/3095 0.514s + 0.002s (eta: 0:00:40)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3027/3095 0.514s + 0.002s (eta: 0:00:35)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3037/3095 0.513s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3047/3095 0.512s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3057/3095 0.513s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3067/3095 0.513s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3077/3095 0.513s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [2477, 3095] of 4952: 3087/3095 0.512s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_2476_3095.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 5 with range [3096, 3714]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3095, 3714], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3096/3714 0.670s + 0.002s (eta: 0:06:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3106/3714 0.540s + 0.002s (eta: 0:05:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3116/3714 0.522s + 0.002s (eta: 0:05:12)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3126/3714 0.515s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3136/3714 0.513s + 0.002s (eta: 0:04:57)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3146/3714 0.513s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3156/3714 0.517s + 0.002s (eta: 0:04:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3166/3714 0.523s + 0.002s (eta: 0:04:47)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3176/3714 0.521s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3186/3714 0.517s + 0.002s (eta: 0:04:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3196/3714 0.515s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3206/3714 0.512s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3216/3714 0.514s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3226/3714 0.512s + 0.002s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3236/3714 0.511s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3246/3714 0.512s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3256/3714 0.510s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3266/3714 0.507s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3276/3714 0.506s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3286/3714 0.504s + 0.002s (eta: 0:03:36)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3296/3714 0.504s + 0.002s (eta: 0:03:31)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3306/3714 0.504s + 0.002s (eta: 0:03:26)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3316/3714 0.503s + 0.002s (eta: 0:03:20)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3326/3714 0.504s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3336/3714 0.502s + 0.002s (eta: 0:03:10)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3346/3714 0.501s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3356/3714 0.501s + 0.002s (eta: 0:02:59)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3366/3714 0.501s + 0.002s (eta: 0:02:55)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3376/3714 0.501s + 0.002s (eta: 0:02:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3386/3714 0.500s + 0.002s (eta: 0:02:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3396/3714 0.498s + 0.002s (eta: 0:02:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3406/3714 0.498s + 0.002s (eta: 0:02:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3416/3714 0.498s + 0.002s (eta: 0:02:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3426/3714 0.499s + 0.002s (eta: 0:02:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3436/3714 0.498s + 0.002s (eta: 0:02:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3446/3714 0.499s + 0.002s (eta: 0:02:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3456/3714 0.498s + 0.002s (eta: 0:02:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3466/3714 0.498s + 0.002s (eta: 0:02:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3476/3714 0.497s + 0.002s (eta: 0:01:58)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3486/3714 0.498s + 0.002s (eta: 0:01:53)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3496/3714 0.498s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3506/3714 0.497s + 0.002s (eta: 0:01:43)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3516/3714 0.497s + 0.002s (eta: 0:01:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3526/3714 0.498s + 0.002s (eta: 0:01:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3536/3714 0.499s + 0.002s (eta: 0:01:29)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3546/3714 0.498s + 0.002s (eta: 0:01:24)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3556/3714 0.498s + 0.002s (eta: 0:01:19)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3566/3714 0.499s + 0.002s (eta: 0:01:14)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3576/3714 0.498s + 0.002s (eta: 0:01:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3586/3714 0.498s + 0.002s (eta: 0:01:03)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3596/3714 0.498s + 0.002s (eta: 0:00:58)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3606/3714 0.498s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3616/3714 0.498s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3626/3714 0.498s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3636/3714 0.497s + 0.002s (eta: 0:00:38)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3646/3714 0.498s + 0.002s (eta: 0:00:33)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3656/3714 0.498s + 0.002s (eta: 0:00:28)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3666/3714 0.497s + 0.002s (eta: 0:00:23)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3676/3714 0.497s + 0.002s (eta: 0:00:18)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3686/3714 0.497s + 0.002s (eta: 0:00:13)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3696/3714 0.497s + 0.002s (eta: 0:00:08)
INFO test_engine.py: 281: im_detect: range [3096, 3714] of 4952: 3706/3714 0.496s + 0.002s (eta: 0:00:03)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3095_3714.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 6 with range [3715, 4333]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[3714, 4333], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3715/4333 0.660s + 0.002s (eta: 0:06:48)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3725/4333 0.502s + 0.002s (eta: 0:05:06)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3735/4333 0.489s + 0.002s (eta: 0:04:53)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3745/4333 0.495s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3755/4333 0.488s + 0.002s (eta: 0:04:43)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3765/4333 0.503s + 0.002s (eta: 0:04:46)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3775/4333 0.508s + 0.002s (eta: 0:04:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3785/4333 0.500s + 0.002s (eta: 0:04:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3795/4333 0.496s + 0.002s (eta: 0:04:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3805/4333 0.501s + 0.002s (eta: 0:04:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3815/4333 0.502s + 0.002s (eta: 0:04:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3825/4333 0.506s + 0.002s (eta: 0:04:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3835/4333 0.506s + 0.002s (eta: 0:04:12)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3845/4333 0.505s + 0.002s (eta: 0:04:07)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3855/4333 0.507s + 0.002s (eta: 0:04:03)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3865/4333 0.510s + 0.002s (eta: 0:03:59)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3875/4333 0.509s + 0.002s (eta: 0:03:54)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3885/4333 0.509s + 0.002s (eta: 0:03:48)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3895/4333 0.511s + 0.002s (eta: 0:03:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3905/4333 0.510s + 0.002s (eta: 0:03:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3915/4333 0.510s + 0.002s (eta: 0:03:33)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3925/4333 0.508s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3935/4333 0.510s + 0.002s (eta: 0:03:23)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3945/4333 0.509s + 0.002s (eta: 0:03:18)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3955/4333 0.507s + 0.002s (eta: 0:03:12)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3965/4333 0.509s + 0.002s (eta: 0:03:07)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3975/4333 0.510s + 0.002s (eta: 0:03:03)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3985/4333 0.512s + 0.002s (eta: 0:02:58)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 3995/4333 0.510s + 0.002s (eta: 0:02:52)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4005/4333 0.507s + 0.002s (eta: 0:02:47)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4015/4333 0.508s + 0.002s (eta: 0:02:42)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4025/4333 0.510s + 0.002s (eta: 0:02:37)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4035/4333 0.511s + 0.002s (eta: 0:02:32)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4045/4333 0.512s + 0.002s (eta: 0:02:27)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4055/4333 0.511s + 0.002s (eta: 0:02:22)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4065/4333 0.511s + 0.002s (eta: 0:02:17)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4075/4333 0.511s + 0.002s (eta: 0:02:12)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4085/4333 0.510s + 0.002s (eta: 0:02:07)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4095/4333 0.508s + 0.002s (eta: 0:02:01)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4105/4333 0.509s + 0.002s (eta: 0:01:56)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4115/4333 0.508s + 0.002s (eta: 0:01:51)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4125/4333 0.508s + 0.002s (eta: 0:01:46)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4135/4333 0.508s + 0.002s (eta: 0:01:41)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4145/4333 0.508s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4155/4333 0.508s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4165/4333 0.508s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4175/4333 0.508s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4185/4333 0.508s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4195/4333 0.508s + 0.002s (eta: 0:01:10)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4205/4333 0.509s + 0.002s (eta: 0:01:05)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4215/4333 0.510s + 0.002s (eta: 0:01:00)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4225/4333 0.510s + 0.002s (eta: 0:00:55)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4235/4333 0.509s + 0.002s (eta: 0:00:50)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4245/4333 0.508s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4255/4333 0.508s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4265/4333 0.508s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4275/4333 0.508s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4285/4333 0.508s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4295/4333 0.507s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4305/4333 0.508s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4315/4333 0.507s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [3715, 4333] of 4952: 4325/4333 0.506s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_3714_4333.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO subprocess.py: 129: # ---------------------------------------------------------------------------- #
INFO subprocess.py: 131: stdout of subprocess 7 with range [4334, 4952]
INFO subprocess.py: 133: # ---------------------------------------------------------------------------- #
INFO test_net.py:  72: Called with args:
INFO test_net.py:  73: Namespace(cfg_file='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_config.yaml', dataset=None, load_ckpt='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth', load_detectron=None, multi_gpu_testing=False, num_classes=None, output_dir='Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test', range=[4333, 4952], set_cfgs=['TEST.DATASETS', '("voc_2007_test",)'], vis=False)
INFO test_net.py: 130: Testing with config:
INFO test_net.py: 131: {'BBOX_XFORM_CLIP': 4.135166556742356,
 'CROP_RESIZE_WITH_MAX_POOL': True,
 'CUDA': False,
 'DATA_DIR': '/home/ubuntu/Detectron.pytorch/data',
 'DATA_LOADER': {'NUM_THREADS': 4},
 'DEBUG': False,
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXPECTED_RESULTS': [],
 'EXPECTED_RESULTS_ATOL': 0.005,
 'EXPECTED_RESULTS_EMAIL': '',
 'EXPECTED_RESULTS_RTOL': 0.1,
 'FAST_RCNN': {'BOX_OUT_STREAMS': 1,
               'CONV_HEAD_DIM': 256,
               'MLP_HEAD_DIM': 1024,
               'NUM_STACKED_CONVS': 4,
               'ROI_BOX_HEAD': 'fast_rcnn_heads.roi_2mlp_head',
               'ROI_XFORM_METHOD': 'RoIAlign',
               'ROI_XFORM_RESOLUTION': 7,
               'ROI_XFORM_SAMPLING_RATIO': 2},
 'FPN': {'COARSEST_STRIDE': 32,
         'DIM': 256,
         'EXTRA_CONV_LEVELS': False,
         'FPN_ON': True,
         'MULTILEVEL_ROIS': True,
         'MULTILEVEL_RPN': True,
         'ROI_CANONICAL_LEVEL': 4,
         'ROI_CANONICAL_SCALE': 224,
         'ROI_MAX_LEVEL': 5,
         'ROI_MIN_LEVEL': 2,
         'RPN_ANCHOR_START_SIZE': 32,
         'RPN_ASPECT_RATIOS': (0.5, 1, 2),
         'RPN_COLLECT_SCALE': 1,
         'RPN_MAX_LEVEL': 6,
         'RPN_MIN_LEVEL': 2,
         'USE_GN': False,
         'ZERO_INIT_LATERAL': False},
 'GROUP_NORM': {'DIM_PER_GP': -1, 'EPSILON': 1e-05, 'NUM_GROUPS': 32},
 'KRCNN': {'CONV_HEAD_DIM': 256,
           'CONV_HEAD_KERNEL': 3,
           'CONV_INIT': 'GaussianFill',
           'DECONV_DIM': 256,
           'DECONV_KERNEL': 4,
           'DILATION': 1,
           'HEATMAP_SIZE': -1,
           'INFERENCE_MIN_SIZE': 0,
           'KEYPOINT_CONFIDENCE': 'bbox',
           'LOSS_WEIGHT': 1.0,
           'MIN_KEYPOINT_COUNT_FOR_VALID_MINIBATCH': 20,
           'NMS_OKS': False,
           'NORMALIZE_BY_VISIBLE_KEYPOINTS': True,
           'NUM_KEYPOINTS': -1,
           'NUM_STACKED_CONVS': 8,
           'ROI_KEYPOINTS_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'UP_SCALE': -1,
           'USE_DECONV': False,
           'USE_DECONV_OUTPUT': False},
 'MATLAB': 'matlab',
 'MODEL': {'BBOX_REG_WEIGHTS': (10.0, 10.0, 5.0, 5.0),
           'CLS_AGNOSTIC_BBOX_REG': False,
           'CONV_BODY': 'FPN.fpn_ResNet101_conv5_body',
           'FASTER_RCNN': True,
           'KEYPOINTS_ON': False,
           'LOAD_IMAGENET_PRETRAINED_WEIGHTS': True,
           'MASK_ON': False,
           'NUM_CLASSES': 21,
           'RPN_ONLY': False,
           'SHARE_RES5': False,
           'TYPE': 'generalized_rcnn',
           'UNSUPERVISED_POSE': False},
 'MRCNN': {'CLS_SPECIFIC_MASK': True,
           'CONV_INIT': 'GaussianFill',
           'DILATION': 2,
           'DIM_REDUCED': 256,
           'MEMORY_EFFICIENT_LOSS': True,
           'RESOLUTION': 14,
           'ROI_MASK_HEAD': '',
           'ROI_XFORM_METHOD': 'RoIAlign',
           'ROI_XFORM_RESOLUTION': 7,
           'ROI_XFORM_SAMPLING_RATIO': 0,
           'THRESH_BINARIZE': 0.5,
           'UPSAMPLE_RATIO': 1,
           'USE_FC_OUTPUT': False,
           'WEIGHT_LOSS_MASK': 1.0},
 'NUM_GPUS': 4,
 'OUTPUT_DIR': 'Outputs',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'POOLING_MODE': 'crop',
 'POOLING_SIZE': 7,
 'PYTORCH_VERSION_LESS_THAN_040': False,
 'RESNETS': {'FREEZE_AT': 2,
             'IMAGENET_PRETRAINED_WEIGHTS': 'data/pretrained_model/resnet101_caffe.pth',
             'NUM_GROUPS': 1,
             'RES5_DILATION': 1,
             'SHORTCUT_FUNC': 'basic_bn_shortcut',
             'STEM_FUNC': 'basic_bn_stem',
             'STRIDE_1X1': True,
             'TRANS_FUNC': 'bottleneck_transformation',
             'USE_GN': False,
             'WIDTH_PER_GROUP': 64},
 'RETINANET': {'ANCHOR_SCALE': 4,
               'ASPECT_RATIOS': (0.5, 1.0, 2.0),
               'BBOX_REG_BETA': 0.11,
               'BBOX_REG_WEIGHT': 1.0,
               'CLASS_SPECIFIC_BBOX': False,
               'INFERENCE_TH': 0.05,
               'LOSS_ALPHA': 0.25,
               'LOSS_GAMMA': 2.0,
               'NEGATIVE_OVERLAP': 0.4,
               'NUM_CONVS': 4,
               'POSITIVE_OVERLAP': 0.5,
               'PRE_NMS_TOP_N': 1000,
               'PRIOR_PROB': 0.01,
               'RETINANET_ON': False,
               'SCALES_PER_OCTAVE': 3,
               'SHARE_CLS_BBOX_TOWER': False,
               'SOFTMAX': False},
 'RFCN': {'PS_GRID_SIZE': 3},
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/Detectron.pytorch',
 'RPN': {'ASPECT_RATIOS': (0.5, 1, 2),
         'CLS_ACTIVATION': 'sigmoid',
         'OUT_DIM': 512,
         'OUT_DIM_AS_IN_DIM': True,
         'RPN_ON': True,
         'SIZES': (64, 128, 256, 512),
         'STRIDE': 16},
 'SOLVER': {'BASE_LR': 1e-05,
            'BIAS_DOUBLE_LR': True,
            'BIAS_WEIGHT_DECAY': False,
            'GAMMA': 0.1,
            'LOG_LR_CHANGE_THRESHOLD': 1.1,
            'LRS': [],
            'LR_POLICY': 'steps_with_decay',
            'MAX_ITER': 30000,
            'MOMENTUM': 0.9,
            'SCALE_MOMENTUM': True,
            'SCALE_MOMENTUM_THRESHOLD': 1.1,
            'STEPS': [0, 10000, 20000],
            'STEP_SIZE': 30000,
            'TYPE': 'SGD',
            'WARM_UP_FACTOR': 0.3333333333333333,
            'WARM_UP_ITERS': 500,
            'WARM_UP_METHOD': 'linear',
            'WEIGHT_DECAY': 0.1,
            'WEIGHT_DECAY_GN': 0.0},
 'TEST': {'BBOX_AUG': {'AREA_TH_HI': 32400,
                       'AREA_TH_LO': 2500,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'COORD_HEUR': 'UNION',
                       'ENABLED': False,
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False,
                       'SCORE_HEUR': 'UNION'},
          'BBOX_REG': True,
          'BBOX_VOTE': {'ENABLED': False,
                        'SCORING_METHOD': 'ID',
                        'SCORING_METHOD_BETA': 1.0,
                        'VOTE_TH': 0.8},
          'COMPETITION_MODE': True,
          'DATASETS': ('voc_2007_test',),
          'DETECTIONS_PER_IM': 100,
          'FORCE_JSON_DATASET_EVAL': False,
          'KPS_AUG': {'AREA_TH': 32400,
                      'ASPECT_RATIOS': (),
                      'ASPECT_RATIO_H_FLIP': False,
                      'ENABLED': False,
                      'HEUR': 'HM_AVG',
                      'H_FLIP': False,
                      'MAX_SIZE': 4000,
                      'SCALES': (),
                      'SCALE_H_FLIP': False,
                      'SCALE_SIZE_DEP': False},
          'MASK_AUG': {'AREA_TH': 32400,
                       'ASPECT_RATIOS': (),
                       'ASPECT_RATIO_H_FLIP': False,
                       'ENABLED': False,
                       'HEUR': 'SOFT_AVG',
                       'H_FLIP': False,
                       'MAX_SIZE': 4000,
                       'SCALES': (),
                       'SCALE_H_FLIP': False,
                       'SCALE_SIZE_DEP': False},
          'MAX_SIZE': 1000,
          'NMS': 0.5,
          'PRECOMPUTED_PROPOSALS': False,
          'PROPOSAL_FILES': (),
          'PROPOSAL_LIMIT': 2000,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALE': 600,
          'SCORE_THRESH': 0.05,
          'SOFT_NMS': {'ENABLED': False, 'METHOD': 'linear', 'SIGMA': 0.5},
          'WEAK_SUPERVISE': False},
 'TRAIN': {'ASPECT_CROPPING': False,
           'ASPECT_GROUPING': True,
           'ASPECT_HI': 2,
           'ASPECT_LO': 0.5,
           'BATCH_SIZE_PER_IM': 512,
           'BBOX_INSIDE_WEIGHTS': (1.0, 1.0, 1.0, 1.0),
           'BBOX_NORMALIZE_MEANS': (0.0, 0.0, 0.0, 0.0),
           'BBOX_NORMALIZE_STDS': (0.1, 0.1, 0.2, 0.2),
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': False,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'COPY_CLS_TO_DET': False,
           'CROWD_FILTER_THRESH': 0.7,
           'DATASETS': (),
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FREEZE_BOX_HEAD': False,
           'FREEZE_CONV_BODY': False,
           'FREEZE_RPN': False,
           'GT_MIN_AREA': -1,
           'IMS_PER_BATCH': 4,
           'MAX_SIZE': 1000,
           'OL_PSEUDO_LABEL': False,
           'PROPOSAL_FILES': (),
           'RPN_BATCH_SIZE_PER_IM': 256,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 2000,
           'RPN_STRADDLE_THRESH': 0,
           'SCALES': (600,),
           'SNAPSHOT_ITERS': 10000,
           'SPATIAL_REG': False,
           'USE_FLIPPED': True,
           'WEAK_SUPERVISE': False,
           'WEAK_SUPERVISE_WITH_PRETRAIN': False},
 'VIS': False,
 'VIS_TH': 0.9}
loading annotations into memory...
Done (t=0.09s)
creating index...
index created!
INFO test_engine.py: 324: training mode? : False
INFO test_engine.py: 331: loading checkpoint Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/ckpt/model_step39999.pth
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4334/4952 0.630s + 0.004s (eta: 0:06:31)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4344/4952 0.538s + 0.002s (eta: 0:05:27)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4354/4952 0.506s + 0.002s (eta: 0:05:03)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4364/4952 0.496s + 0.002s (eta: 0:04:52)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4374/4952 0.499s + 0.003s (eta: 0:04:50)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4384/4952 0.493s + 0.002s (eta: 0:04:41)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4394/4952 0.496s + 0.002s (eta: 0:04:38)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4404/4952 0.494s + 0.002s (eta: 0:04:32)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4414/4952 0.497s + 0.002s (eta: 0:04:28)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4424/4952 0.499s + 0.002s (eta: 0:04:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4434/4952 0.502s + 0.002s (eta: 0:04:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4444/4952 0.503s + 0.002s (eta: 0:04:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4454/4952 0.502s + 0.002s (eta: 0:04:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4464/4952 0.501s + 0.002s (eta: 0:04:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4474/4952 0.500s + 0.002s (eta: 0:04:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4484/4952 0.502s + 0.002s (eta: 0:03:55)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4494/4952 0.503s + 0.002s (eta: 0:03:51)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4504/4952 0.505s + 0.002s (eta: 0:03:47)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4514/4952 0.506s + 0.002s (eta: 0:03:42)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4524/4952 0.505s + 0.002s (eta: 0:03:37)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4534/4952 0.505s + 0.002s (eta: 0:03:32)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4544/4952 0.506s + 0.002s (eta: 0:03:27)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4554/4952 0.503s + 0.002s (eta: 0:03:21)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4564/4952 0.504s + 0.002s (eta: 0:03:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4574/4952 0.504s + 0.002s (eta: 0:03:11)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4584/4952 0.503s + 0.002s (eta: 0:03:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4594/4952 0.505s + 0.002s (eta: 0:03:01)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4604/4952 0.504s + 0.002s (eta: 0:02:56)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4614/4952 0.506s + 0.002s (eta: 0:02:51)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4624/4952 0.504s + 0.002s (eta: 0:02:46)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4634/4952 0.504s + 0.002s (eta: 0:02:41)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4644/4952 0.504s + 0.002s (eta: 0:02:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4654/4952 0.505s + 0.002s (eta: 0:02:31)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4664/4952 0.505s + 0.002s (eta: 0:02:26)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4674/4952 0.504s + 0.002s (eta: 0:02:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4684/4952 0.506s + 0.002s (eta: 0:02:16)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4694/4952 0.504s + 0.002s (eta: 0:02:10)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4704/4952 0.504s + 0.002s (eta: 0:02:05)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4714/4952 0.503s + 0.002s (eta: 0:02:00)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4724/4952 0.502s + 0.002s (eta: 0:01:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4734/4952 0.502s + 0.002s (eta: 0:01:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4744/4952 0.503s + 0.002s (eta: 0:01:45)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4754/4952 0.504s + 0.002s (eta: 0:01:40)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4764/4952 0.504s + 0.002s (eta: 0:01:35)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4774/4952 0.505s + 0.002s (eta: 0:01:30)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4784/4952 0.505s + 0.002s (eta: 0:01:25)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4794/4952 0.506s + 0.002s (eta: 0:01:20)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4804/4952 0.505s + 0.002s (eta: 0:01:15)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4814/4952 0.505s + 0.002s (eta: 0:01:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4824/4952 0.504s + 0.002s (eta: 0:01:04)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4834/4952 0.506s + 0.002s (eta: 0:00:59)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4844/4952 0.505s + 0.002s (eta: 0:00:54)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4854/4952 0.505s + 0.002s (eta: 0:00:49)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4864/4952 0.506s + 0.002s (eta: 0:00:44)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4874/4952 0.506s + 0.002s (eta: 0:00:39)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4884/4952 0.505s + 0.002s (eta: 0:00:34)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4894/4952 0.505s + 0.002s (eta: 0:00:29)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4904/4952 0.505s + 0.002s (eta: 0:00:24)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4914/4952 0.505s + 0.002s (eta: 0:00:19)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4924/4952 0.504s + 0.002s (eta: 0:00:14)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4934/4952 0.504s + 0.002s (eta: 0:00:09)
INFO test_engine.py: 281: im_detect: range [4334, 4952] of 4952: 4944/4952 0.504s + 0.002s (eta: 0:00:04)
INFO test_engine.py: 314: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detection_range_4333_4952.pkl
/home/ubuntu/anaconda3/envs/pytorch41/lib/python3.7/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")

INFO test_engine.py: 211: Wrote detections to: /home/ubuntu/Detectron.pytorch/Outputs/e2e_faster_rcnn_R-101-FPN_dt-clipart-VOC/Nov04-20-33-03_ip-172-31-8-158_step/test/detections.pkl
INFO test_engine.py: 161: Total inference time: 335.101s
INFO task_evaluation.py:  77: Evaluating detections
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: aeroplane
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bicycle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bird
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: boat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bottle
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: bus
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: car
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cat
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: chair
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: cow
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: diningtable
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: dog
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: horse
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: motorbike
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: person
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: pottedplant
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sheep
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: sofa
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: train
INFO voc_dataset_evaluator.py:  74: Writing VOC results for: tvmonitor
INFO voc_dataset_evaluator.py: 115: VOC07 metric? Yes
INFO voc_eval.py: 171: [1833 1788 1068 ...  376 1455  125]
INFO voc_dataset_evaluator.py: 127: AP for aeroplane = 0.7864
INFO voc_eval.py: 171: [1004  324 1403 ...  980 1510 1741]
INFO voc_dataset_evaluator.py: 127: AP for bicycle = 0.8201
INFO voc_eval.py: 171: [ 917 1857 1507 ... 1348  204  974]
INFO voc_dataset_evaluator.py: 127: AP for bird = 0.7225
INFO voc_eval.py: 171: [2259 3178  130 ... 1202 3222  686]
INFO voc_dataset_evaluator.py: 127: AP for boat = 0.6473
INFO voc_eval.py: 171: [1509 2838  218 ... 3487  253 3656]
INFO voc_dataset_evaluator.py: 127: AP for bottle = 0.6468
INFO voc_eval.py: 171: [ 572 1498 1239 ...  373  615  679]
INFO voc_dataset_evaluator.py: 127: AP for bus = 0.7940
INFO voc_eval.py: 171: [5012 7720 6676 ... 6974 2602 7585]
INFO voc_dataset_evaluator.py: 127: AP for car = 0.8600
INFO voc_eval.py: 171: [ 666   79  366 ...  642 1329    4]
INFO voc_dataset_evaluator.py: 127: AP for cat = 0.8229
INFO voc_eval.py: 171: [ 218  219 5479 ... 8455 5991 1620]
INFO voc_dataset_evaluator.py: 127: AP for chair = 0.6136
INFO voc_eval.py: 171: [1164  691 1163 ...  209  918  627]
INFO voc_dataset_evaluator.py: 127: AP for cow = 0.7765
INFO voc_eval.py: 171: [ 904 1207 2501 ... 1753 2752 1105]
INFO voc_dataset_evaluator.py: 127: AP for diningtable = 0.6763
INFO voc_eval.py: 171: [1298  131  531 ...  661  297 1301]
INFO voc_dataset_evaluator.py: 127: AP for dog = 0.8079
INFO voc_eval.py: 171: [  46  168  548 ...  568  653 1683]
INFO voc_dataset_evaluator.py: 127: AP for horse = 0.8198
INFO voc_eval.py: 171: [ 586 1877  322 ... 1814 1080 1577]
INFO voc_dataset_evaluator.py: 127: AP for motorbike = 0.7831
INFO voc_eval.py: 171: [ 9140 11047 23289 ...  3753 10802  5812]
INFO voc_dataset_evaluator.py: 127: AP for person = 0.8284
INFO voc_eval.py: 171: [1470 3935 1539 ... 2443  215  125]
INFO voc_dataset_evaluator.py: 127: AP for pottedplant = 0.4596
INFO voc_eval.py: 171: [  71  537 1230 ...   30 1670  351]
INFO voc_dataset_evaluator.py: 127: AP for sheep = 0.7594
INFO voc_eval.py: 171: [1142 1688  419 ... 1804  652  194]
INFO voc_dataset_evaluator.py: 127: AP for sofa = 0.7279
INFO voc_eval.py: 171: [ 220 1656   39 ...  542  183  386]
INFO voc_dataset_evaluator.py: 127: AP for train = 0.7918
INFO voc_eval.py: 171: [ 896  240  586 ... 1171  326 1460]
INFO voc_dataset_evaluator.py: 127: AP for tvmonitor = 0.7317
INFO voc_dataset_evaluator.py: 130: Mean AP = 0.7438
INFO voc_dataset_evaluator.py: 131: ~~~~~~~~
INFO voc_dataset_evaluator.py: 132: Results:
INFO voc_dataset_evaluator.py: 134: 0.786
INFO voc_dataset_evaluator.py: 134: 0.820
INFO voc_dataset_evaluator.py: 134: 0.722
INFO voc_dataset_evaluator.py: 134: 0.647
INFO voc_dataset_evaluator.py: 134: 0.647
INFO voc_dataset_evaluator.py: 134: 0.794
INFO voc_dataset_evaluator.py: 134: 0.860
INFO voc_dataset_evaluator.py: 134: 0.823
INFO voc_dataset_evaluator.py: 134: 0.614
INFO voc_dataset_evaluator.py: 134: 0.777
INFO voc_dataset_evaluator.py: 134: 0.676
INFO voc_dataset_evaluator.py: 134: 0.808
INFO voc_dataset_evaluator.py: 134: 0.820
INFO voc_dataset_evaluator.py: 134: 0.783
INFO voc_dataset_evaluator.py: 134: 0.828
INFO voc_dataset_evaluator.py: 134: 0.460
INFO voc_dataset_evaluator.py: 134: 0.759
INFO voc_dataset_evaluator.py: 134: 0.728
INFO voc_dataset_evaluator.py: 134: 0.792
INFO voc_dataset_evaluator.py: 134: 0.732
INFO voc_dataset_evaluator.py: 135: 0.744
INFO voc_dataset_evaluator.py: 136: ~~~~~~~~
INFO voc_dataset_evaluator.py: 137: 
INFO voc_dataset_evaluator.py: 138: ----------------------------------------------------------
INFO voc_dataset_evaluator.py: 139: Results computed with the **unofficial** Python eval code.
INFO voc_dataset_evaluator.py: 140: Results should be very close to the official MATLAB code.
INFO voc_dataset_evaluator.py: 141: Use `./tools/reval.py --matlab ...` for your paper.
INFO voc_dataset_evaluator.py: 142: -- Thanks, The Management
INFO voc_dataset_evaluator.py: 143: ----------------------------------------------------------
INFO task_evaluation.py:  63: Evaluating bounding boxes is done!
INFO task_evaluation.py: 189: copypaste: Dataset: voc_2007_test
INFO task_evaluation.py: 191: copypaste: Task: box
INFO task_evaluation.py: 194: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 195: copypaste: -1.0000,-1.0000,-1.0000,-1.0000,-1.0000,-1.0000
